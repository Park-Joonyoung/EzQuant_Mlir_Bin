From 43368c34b3ba147d7a0017a7a03632ee81fe9b68 Mon Sep 17 00:00:00 2001
From: Park Joon-young <sparkjy18@gmail.com>
Date: Mon, 8 Sep 2025 06:54:18 +0000
Subject: [PATCH] feat: add BiasContract, DequantContract, DequantSplit, and
 ReshapeTo4D passes

---
 tensorflow/compiler/mlir/BUILD                |  277 ++
 tensorflow/compiler/mlir/lite/BUILD           | 2525 +++++++++++++++++
 tensorflow/compiler/mlir/lite/BiasContract.cc |  126 +
 tensorflow/compiler/mlir/lite/BiasContract.h  |   35 +
 .../compiler/mlir/lite/DequantContract.cc     |   94 +
 .../compiler/mlir/lite/DequantContract.h      |   35 +
 tensorflow/compiler/mlir/lite/DequantSplit.cc |   94 +
 tensorflow/compiler/mlir/lite/DequantSplit.h  |   35 +
 tensorflow/compiler/mlir/lite/ReshapeTo4D.cc  |  118 +
 tensorflow/compiler/mlir/lite/ReshapeTo4D.h   |   35 +
 .../compiler/mlir/lite/transforms/passes.h    |  368 +++
 .../compiler/mlir/lite/transforms/passes.td   |  422 +++
 12 files changed, 4164 insertions(+)
 create mode 100644 tensorflow/compiler/mlir/BUILD
 create mode 100644 tensorflow/compiler/mlir/lite/BUILD
 create mode 100644 tensorflow/compiler/mlir/lite/BiasContract.cc
 create mode 100644 tensorflow/compiler/mlir/lite/BiasContract.h
 create mode 100644 tensorflow/compiler/mlir/lite/DequantContract.cc
 create mode 100644 tensorflow/compiler/mlir/lite/DequantContract.h
 create mode 100644 tensorflow/compiler/mlir/lite/DequantSplit.cc
 create mode 100644 tensorflow/compiler/mlir/lite/DequantSplit.h
 create mode 100644 tensorflow/compiler/mlir/lite/ReshapeTo4D.cc
 create mode 100644 tensorflow/compiler/mlir/lite/ReshapeTo4D.h
 create mode 100644 tensorflow/compiler/mlir/lite/transforms/passes.h
 create mode 100644 tensorflow/compiler/mlir/lite/transforms/passes.td

diff --git a/tensorflow/compiler/mlir/BUILD b/tensorflow/compiler/mlir/BUILD
new file mode 100644
index 00000000000..c8cd50dfdb6
--- /dev/null
+++ b/tensorflow/compiler/mlir/BUILD
@@ -0,0 +1,277 @@
+# Description:
+#   TensorFlow/TensorFlow Lite/XLA MLIR dialects and tools.
+
+load(
+    "//tensorflow:tensorflow.bzl",
+    "tf_cc_binary",
+    "tf_cc_test",
+)
+load("//tensorflow:tensorflow.default.bzl", "filegroup")
+load("//tensorflow/core/platform:rules_cc.bzl", "cc_library")
+
+package(
+    # copybara:uncomment default_applicable_licenses = ["//tensorflow:license"],
+    default_visibility = ["//visibility:public"],
+    licenses = ["notice"],
+)
+
+package_group(
+    name = "subpackages",
+    packages = ["//tensorflow/compiler/mlir/..."],
+)
+
+exports_files(glob(["g3doc/*.md"] + ["g3doc/_includes/tf_passes.md"]))
+
+# To reference all tablegen files here when checking for updates to them.
+filegroup(
+    name = "td_files",
+    srcs = glob(["**/*.td"]),
+)
+
+cc_library(
+    name = "op_or_arg_name_mapper",
+    srcs = ["op_or_arg_name_mapper.cc"],
+    hdrs = ["op_or_arg_name_mapper.h"],
+    deps = [
+        "//tensorflow/compiler/mlir/utils:name_utils",
+        "@com_google_absl//absl/strings",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+cc_library(
+    name = "tf_mlir_opt_main",
+    testonly = True,
+    srcs = ["tf_mlir_opt_main.cc"],
+    deps = [
+        ":init_mlir",
+        ":passes",
+        ":register_common_dialects",
+        "//tensorflow/compiler/mlir/lite:tensorflow_lite",
+        "//tensorflow/compiler/mlir/lite:tf_tfl_passes",  # buildcleaner:keep
+        "//tensorflow/compiler/mlir/quantization/stablehlo:bridge_passes",
+        "//tensorflow/compiler/mlir/tensorflow:mlprogram_util",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:tensorflow_passes",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:tensorflow_test_passes",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:tf_graph_optimization_pass",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:tf_saved_model_passes",  # buildcleaner:keep
+        "//tensorflow/compiler/mlir/tensorflow/transforms/host_runtime:lower_cluster_to_runtime_ops",
+        "//tensorflow/compiler/mlir/tensorflow/transforms/host_runtime:runtime_passes",
+        "//tensorflow/compiler/mlir/tensorflow/transforms/sparsecore:sparsecore_passes",
+        "//tensorflow/compiler/mlir/tf2xla:compile_mlir_util",
+        "//tensorflow/compiler/mlir/tf2xla/internal/passes:clustering_passes",
+        "//tensorflow/compiler/mlir/tf2xla/internal/passes:mlir_to_graph_passes",
+        "//tensorflow/compiler/mlir/tf2xla/transforms:tf_xla_passes",
+        "//tensorflow/compiler/mlir/tf2xla/transforms:xla_legalize_tf",
+        # added DequantSplit, BiasContract, DequantContract, ReshapeTo4D
+        "//tensorflow/compiler/mlir/lite:dequant_split",
+        "//tensorflow/compiler/mlir/lite:bias_contract",
+        "//tensorflow/compiler/mlir/lite:dequant_contract",
+        "//tensorflow/compiler/mlir/lite:reshape_to_4d",
+        "@llvm-project//mlir:AllPassesAndDialects",
+        "@llvm-project//mlir:MlirOptLib",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:Transforms",
+        "@local_xla//xla/mlir/framework/transforms:passes",
+        "@local_xla//xla/mlir_hlo:all_passes",
+    ],
+)
+
+cc_library(
+    name = "passes",
+    visibility = [
+        ":__subpackages__",
+        "//tensorflow/python:__subpackages__",
+    ],
+    deps = [
+        "@llvm-project//mlir:AffineDialect",
+        "@llvm-project//mlir:QuantOps",
+        # Link jit lib to link JIT devices required to run
+        # xla-legalize-tf-with-tf2xla pass.
+        "//tensorflow/compiler/jit",
+        "//tensorflow/compiler/mlir/lite:lift_tflite_flex_ops",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:tensorflow_passes",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:tf_dialect_passes",
+        "//tensorflow/compiler/mlir/tf2xla:compile_mlir_util",
+    ],
+)
+
+cc_library(
+    name = "init_mlir",
+    srcs = ["init_mlir.cc"],
+    hdrs = ["init_mlir.h"],
+    visibility = ["//visibility:public"],
+    deps = [
+        "//tensorflow/core:lib",
+        "@llvm-project//llvm:Support",
+    ],
+)
+
+cc_library(
+    name = "mlir_graph_optimization_pass",
+    srcs = ["mlir_graph_optimization_pass.cc"],
+    hdrs = ["mlir_graph_optimization_pass.h"],
+    deps = [
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:attribute_utils",
+        "//tensorflow/compiler/mlir/tensorflow:device_util",
+        "//tensorflow/compiler/mlir/tensorflow:dump_mlir_util",
+        "//tensorflow/compiler/mlir/tensorflow:mlir_roundtrip_flags",
+        "//tensorflow/compiler/mlir/tf2xla:mlir_bridge_rollout_policy",
+        "//tensorflow/compiler/mlir/tf2xla/api/v2:graph_to_tf_executor",
+        "//tensorflow/compiler/mlir/tf2xla/api/v2:tf_executor_to_graph",
+        "//tensorflow/core:core_cpu",
+        "//tensorflow/core:framework",
+        "//tensorflow/core:lib",
+        "//tensorflow/core:protos_all_cc",
+        "//tensorflow/core/common_runtime:device_set",
+        "//tensorflow/core/protobuf:for_core_protos_cc",
+        "@com_google_absl//absl/container:flat_hash_set",
+        "@com_google_absl//absl/log",
+        "@com_google_absl//absl/log:check",
+        "@com_google_absl//absl/status",
+        "@com_google_absl//absl/strings:string_view",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:FuncExtensions",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:ShapeDialect",
+    ],
+    alwayslink = 1,
+)
+
+cc_library(
+    name = "mlir_graph_optimization_pass_registration",
+    srcs = [
+        "mlir_graph_optimization_pass_registration.cc",
+    ],
+    deps = [
+        ":mlir_graph_optimization_pass",
+        "//tensorflow/core:core_cpu",
+    ],
+    alwayslink = 1,
+)
+
+# This should just be a wrapper around tf_mlir_opt_main. Don't add
+# direct dependencies to this binary.
+tf_cc_binary(
+    name = "tf-opt",
+    testonly = True,
+    deps = [
+        ":tf_mlir_opt_main",
+    ],
+)
+
+tf_cc_binary(
+    name = "tf-reduce",
+    testonly = True,
+    srcs = ["tf_mlir_reduce_main.cc"],
+    deps = [
+        ":init_mlir",
+        ":register_common_dialects",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:tensorflow_reduce_patterns_inc_gen",
+        "@llvm-project//mlir:AllPassesAndDialects",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:MlirReduceLib",
+        "@llvm-project//mlir:Reducer",
+    ],
+)
+
+cc_library(
+    name = "register_common_dialects",
+    testonly = True,
+    srcs = ["register_common_dialects.cc"],
+    hdrs = ["register_common_dialects.h"],
+    deps = [
+        "//tensorflow/compiler/mlir/lite:tensorflow_lite",
+        "//tensorflow/compiler/mlir/lite/quantization/ir:QuantOps",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:mlprogram_util",
+        "//tensorflow/compiler/mlir/tools/kernel_gen/ir:tf_framework_ops",
+        "//tensorflow/core/ir/types:Dialect",
+        "@llvm-project//mlir:AllExtensions",
+        "@llvm-project//mlir:AllPassesAndDialects",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:MlirOptLib",
+        "@llvm-project//mlir:QuantOps",
+        "@llvm-project//mlir:ShapeDialect",
+        "@llvm-project//mlir:TensorDialect",
+        "@llvm-project//mlir:TosaDialect",
+        "@llvm-project//mlir:Transforms",
+        "@local_xla//xla/mlir/framework/ir:xla_framework",
+        "@local_xla//xla/mlir_hlo:hlo_dialect_registration",
+        "@stablehlo//:register",
+    ],
+)
+
+tf_cc_test(
+    name = "register_common_dialects_test",
+    srcs = ["register_common_dialects_test.cc"],
+    deps = [
+        ":register_common_dialects",
+        "@com_google_googletest//:gtest_main",
+        "@llvm-project//mlir:IR",
+    ],
+)
+
+tf_cc_binary(
+    name = "tf-mlir-translate",
+    testonly = True,
+    srcs = ["tf_mlir_translate_main.cc"],
+    deps = [
+        ":init_mlir",
+        "//tensorflow/compiler/mlir/lite/tools:translate_cl_options",
+        "//tensorflow/compiler/mlir/lite/tools:translate_registration",
+        "//tensorflow/compiler/mlir/tensorflow:tf_xla_mlir_translate",
+        "//tensorflow/compiler/mlir/tensorflow:translate_lib",
+        "//tensorflow/compiler/mlir/tf2xla/tests/registration:graph_to_tf_executor_registration",
+        "//tensorflow/core:lib",
+        "//tensorflow/core:tensorflow",
+        "@com_google_absl//absl/strings",
+        "@com_google_absl//absl/types:span",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TranslateLib",
+        "@local_xla//xla/hlo/translate/hlo_to_mhlo:translate_registration",
+        "@local_xla//xla/hlo/translate/mhlo_to_hlo:translate_registration",
+    ],
+)
+
+tf_cc_test(
+    name = "mlir_graph_optimization_pass_test",
+    srcs = ["mlir_graph_optimization_pass_test.cc"],
+    deps = [
+        ":mlir_graph_optimization_pass",
+        "//tensorflow/core:core_cpu",
+        "//tensorflow/core:framework",
+        "//tensorflow/core:ops",
+        "//tensorflow/core:portable_gif_internal",
+        "//tensorflow/core:protos_all_cc",
+        "//tensorflow/core:test",
+        "//tensorflow/core:test_main",
+        "//tensorflow/core/common_runtime:device_set",
+        "//tensorflow/core/common_runtime:optimization_registry",
+        "//tensorflow/core/framework:tensor_testutil",
+        "//tensorflow/core/lib/monitoring:cell_reader",
+        "//tensorflow/core/platform:status",
+        "//tensorflow/core/protobuf:for_core_protos_cc",
+        "@com_google_absl//absl/status",
+        "@com_google_googletest//:gtest_main",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:IR",
+    ],
+)
+
+filegroup(
+    name = "litfiles",
+    srcs = glob(["runlit*py"]),
+    visibility = ["//tensorflow:__subpackages__"],
+)
+
+exports_files(["run_lit.sh"])
diff --git a/tensorflow/compiler/mlir/lite/BUILD b/tensorflow/compiler/mlir/lite/BUILD
new file mode 100644
index 00000000000..5b149a9b725
--- /dev/null
+++ b/tensorflow/compiler/mlir/lite/BUILD
@@ -0,0 +1,2525 @@
+load("@bazel_skylib//lib:selects.bzl", "selects")
+load("@bazel_skylib//rules:build_test.bzl", "build_test")
+load("@bazel_skylib//rules:common_settings.bzl", "bool_flag")
+load("@llvm-project//mlir:tblgen.bzl", "gentbl_cc_library", "td_library")
+
+# Placeholder: load py_proto_library
+load("//tensorflow:tensorflow.bzl", "if_google", "if_oss", "tf_cc_binary", "tf_cc_test", "tf_native_cc_binary")
+load("//tensorflow:tensorflow.default.bzl", "filegroup", "get_compatible_with_portable")
+load("//tensorflow/compiler/mlir/lite:build_def.bzl", "tflite_copts_warnings")
+load(
+    "//tensorflow/core/platform:build_config.bzl",
+    "tf_proto_library",
+)
+load("//tensorflow/core/platform:rules_cc.bzl", "cc_library")
+
+package(
+    # copybara:uncomment default_applicable_licenses = ["//tensorflow:LICENSE"],
+    default_visibility = ["//visibility:public"],
+    licenses = ["notice"],
+)
+
+package_group(
+    name = "friends",
+    packages = [
+        "//learning/brain/experimental/mlir/tflite/tfmrt/...",
+        "//learning/brain/mlir/...",
+        "//third_party/iree/...",
+        "//third_party/odml/infra/...",
+        "//tensorflow/compiler/mlir/...",
+        "//tensorflow/lite/...",
+        "//waymo/accelerator/alpine/tools/...",
+        "//waymo/ml/compiler/mlir/...",
+        # Allow visibility from the mlir language server.
+        "//learning/brain/mlir/mlir_lsp_server/...",
+        "//research/language_modeling/sentence_explorer/ondevice/...",
+        "//learning/brain/research/babelfish/inference/speech_tflite/mlir/...",
+    ],
+)
+
+exports_files(glob([
+    "testdata/*.bin",
+]))
+
+filegroup(
+    name = "tflite_internal_cc_3p_api_deps_src",
+    srcs = [
+        "allocation.cc",
+        "allocation.h",
+        "mmap_allocation.cc",
+    ],
+    visibility = ["//tensorflow/lite:__pkg__"],
+)
+
+td_library(
+    name = "tensorflow_lite_ops_td_files",
+    srcs = [
+        "ir/tfl_op_enums.td",
+        "ir/tfl_op_interfaces.td",
+        "ir/tfl_ops.td",
+    ],
+    compatible_with = get_compatible_with_portable(),
+    deps = [
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib:quantization_td_files",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_ops_td_files",
+        "@llvm-project//mlir:FuncTdFiles",
+        "@llvm-project//mlir:InferTypeOpInterfaceTdFiles",
+        "@llvm-project//mlir:LoopLikeInterfaceTdFiles",
+        "@llvm-project//mlir:OpBaseTdFiles",
+        "@llvm-project//mlir:SideEffectInterfacesTdFiles",
+    ],
+)
+
+td_library(
+    name = "tensorflow_lite_patterns_td_files",
+    srcs = [
+        "transforms/legalize_patterns.td",
+        "transforms/legalize_variables.td",
+        "transforms/optimize_batch_matmul.td",
+        "transforms/optimize_broadcast_like_patterns.td",
+        "transforms/optimize_patterns.td",
+        "transforms/post_quantize_patterns.td",
+        "transforms/prepare_patterns.td",
+        "transforms/quantize_by_converter_patterns.td",
+        "transforms/quantize_patterns.td",
+        "transforms/tensorlist_patterns.td",
+        "utils/utils.td",
+    ],
+    compatible_with = get_compatible_with_portable(),
+    visibility = ["//visibility:private"],
+    deps = [
+        ":tensorflow_lite_ops_td_files",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_ops_td_files",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:tensorflow_optimize_td_files",
+        "@llvm-project//mlir:ArithOpsTdFiles",
+        "@llvm-project//mlir:FuncTdFiles",
+        "@llvm-project//mlir:OpBaseTdFiles",
+    ],
+)
+
+gentbl_cc_library(
+    name = "tensorflow_lite_passes_inc_gen",
+    compatible_with = get_compatible_with_portable(),
+    tbl_outs = [
+        (
+            [
+                "-gen-pass-decls",
+                "-name=TensorFlowLiteTd",
+            ],
+            "transforms/passes.h.inc",
+        ),
+    ],
+    tblgen = "@llvm-project//mlir:mlir-tblgen",
+    td_file = "transforms/passes.td",
+    deps = [
+        "@llvm-project//mlir:PassBaseTdFiles",
+    ],
+)
+
+gentbl_cc_library(
+    name = "tensorflow_lite_ops_inc_gen",
+    compatible_with = get_compatible_with_portable(),
+    tbl_outs = [
+        (
+            ["-gen-op-decls"],
+            "ir/tfl_ops.h.inc",
+        ),
+        (
+            ["-gen-op-defs"],
+            "ir/tfl_ops.cc.inc",
+        ),
+        (
+            [
+                "-gen-dialect-doc",
+                "-dialect=tfl",
+            ],
+            "g3doc/tfl_ops.md",
+        ),
+    ],
+    tblgen = "@llvm-project//mlir:mlir-tblgen",
+    td_file = "ir/tfl_ops.td",
+    deps = [
+        ":tensorflow_lite_ops_td_files",
+    ],
+)
+
+gentbl_cc_library(
+    name = "tensorflow_lite_op_interfaces_inc_gen",
+    compatible_with = get_compatible_with_portable(),
+    tbl_outs = [
+        (
+            ["-gen-op-interface-decls"],
+            "ir/tfl_ops_interface.h.inc",
+        ),
+        (
+            ["-gen-op-interface-defs"],
+            "ir/tfl_ops_interface.cc.inc",
+        ),
+        (
+            ["-gen-dialect-decls"],
+            "ir/tfl_ops_dialect.h.inc",
+        ),
+        (
+            ["-gen-dialect-defs"],
+            "ir/tfl_ops_dialect.cc.inc",
+        ),
+    ],
+    tblgen = "@llvm-project//mlir:mlir-tblgen",
+    td_file = "ir/tfl_op_interfaces.td",
+    deps = [
+        ":tensorflow_lite_ops_td_files",
+    ],
+)
+
+gentbl_cc_library(
+    name = "tensorflow_lite_op_enums_inc_gen",
+    compatible_with = get_compatible_with_portable(),
+    tbl_outs = [
+        (
+            ["-gen-enum-decls"],
+            "ir/tfl_ops_enums.h.inc",
+        ),
+        (
+            ["-gen-enum-defs"],
+            "ir/tfl_ops_enums.cc.inc",
+        ),
+        (
+            ["-gen-attrdef-decls"],
+            "ir/tfl_ops_attrdefs.h.inc",
+        ),
+        (
+            ["-gen-attrdef-defs"],
+            "ir/tfl_ops_attrdefs.cc.inc",
+        ),
+    ],
+    tblgen = "@llvm-project//mlir:mlir-tblgen",
+    td_file = "ir/tfl_op_enums.td",
+    deps = [
+        ":tensorflow_lite_ops_td_files",
+    ],
+)
+
+gentbl_cc_library(
+    name = "tensorflow_lite_prepare_tf_inc_gen",
+    compatible_with = get_compatible_with_portable(),
+    tbl_outs = [
+        (
+            ["-gen-rewriters"],
+            "transforms/generated_prepare_tf.inc",
+        ),
+    ],
+    tblgen = "@llvm-project//mlir:mlir-tblgen",
+    td_file = "transforms/prepare_patterns.td",
+    deps = [":tensorflow_lite_patterns_td_files"],
+)
+
+gentbl_cc_library(
+    name = "tensorflow_lite_lower_static_tensor_list_inc_gen",
+    compatible_with = get_compatible_with_portable(),
+    tbl_outs = [
+        (
+            ["-gen-rewriters"],
+            "transforms/generated_lower_static_tensor_list.inc",
+        ),
+    ],
+    tblgen = "@llvm-project//mlir:mlir-tblgen",
+    td_file = "transforms/tensorlist_patterns.td",
+    deps = [":tensorflow_lite_patterns_td_files"],
+)
+
+gentbl_cc_library(
+    name = "tensorflow_lite_legalize_tf_inc_gen",
+    compatible_with = get_compatible_with_portable(),
+    tbl_outs = [
+        (
+            ["-gen-rewriters"],
+            "transforms/generated_legalize_tf.inc",
+        ),
+    ],
+    tblgen = "@llvm-project//mlir:mlir-tblgen",
+    td_file = "transforms/legalize_patterns.td",
+    deps = [":tensorflow_lite_patterns_td_files"],
+)
+
+gentbl_cc_library(
+    name = "tensorflow_lite_legalize_variables_inc_gen",
+    compatible_with = get_compatible_with_portable(),
+    tbl_outs = [
+        (
+            ["-gen-rewriters"],
+            "transforms/generated_legalize_variables.inc",
+        ),
+    ],
+    tblgen = "@llvm-project//mlir:mlir-tblgen",
+    td_file = "transforms/legalize_variables.td",
+    deps = [":tensorflow_lite_patterns_td_files"],
+)
+
+gentbl_cc_library(
+    name = "tensorflow_lite_optimize_inc_gen",
+    compatible_with = get_compatible_with_portable(),
+    tbl_outs = [
+        (
+            ["-gen-rewriters"],
+            "transforms/generated_optimize.inc",
+        ),
+    ],
+    tblgen = "@llvm-project//mlir:mlir-tblgen",
+    td_file = "transforms/optimize_patterns.td",
+    deps = [":tensorflow_lite_patterns_td_files"],
+)
+
+gentbl_cc_library(
+    name = "tensorflow_lite_optimize_batch_matmul_inc_gen",
+    compatible_with = get_compatible_with_portable(),
+    tbl_outs = [
+        (
+            ["-gen-rewriters"],
+            "transforms/generated_optimize_batch_matmul.inc",
+        ),
+    ],
+    tblgen = "@llvm-project//mlir:mlir-tblgen",
+    td_file = "transforms/optimize_batch_matmul.td",
+    deps = [":tensorflow_lite_patterns_td_files"],
+)
+
+gentbl_cc_library(
+    name = "optimize_broadcast_like_inc_gen",
+    compatible_with = get_compatible_with_portable(),
+    tbl_outs = [
+        (
+            ["-gen-rewriters"],
+            "transforms/generated_optimize_broadcast_like.inc",
+        ),
+    ],
+    tblgen = "@llvm-project//mlir:mlir-tblgen",
+    td_file = "transforms/optimize_broadcast_like_patterns.td",
+    deps = [":tensorflow_lite_patterns_td_files"],
+)
+
+gentbl_cc_library(
+    name = "tensorflow_lite_quantize_inc_gen",
+    compatible_with = get_compatible_with_portable(),
+    tbl_outs = [
+        (
+            ["-gen-rewriters"],
+            "transforms/generated_quantize.inc",
+        ),
+    ],
+    tblgen = "@llvm-project//mlir:mlir-tblgen",
+    td_file = "transforms/quantize_patterns.td",
+    deps = [":tensorflow_lite_patterns_td_files"],
+)
+
+gentbl_cc_library(
+    name = "tensorflow_lite_quantize_by_converter_inc_gen",
+    compatible_with = get_compatible_with_portable(),
+    tbl_outs = [
+        (
+            ["-gen-rewriters"],
+            "transforms/generated_quantize_by_converter.inc",
+        ),
+    ],
+    tblgen = "@llvm-project//mlir:mlir-tblgen",
+    td_file = "transforms/quantize_by_converter_patterns.td",
+    deps = [":tensorflow_lite_patterns_td_files"],
+)
+
+gentbl_cc_library(
+    name = "tensorflow_lite_post_quantize_inc_gen",
+    compatible_with = get_compatible_with_portable(),
+    tbl_outs = [
+        (
+            ["-gen-rewriters"],
+            "transforms/generated_post_quantize.inc",
+        ),
+    ],
+    tblgen = "@llvm-project//mlir:mlir-tblgen",
+    td_file = "transforms/post_quantize_patterns.td",
+    deps = [":tensorflow_lite_patterns_td_files"],
+)
+
+gentbl_cc_library(
+    name = "tensorflow_lite_legalize_tensorlist_inc_gen",
+    compatible_with = get_compatible_with_portable(),
+    tbl_outs = [
+        (
+            ["-gen-rewriters"],
+            "transforms/generated_legalize_tensorlist.inc",
+        ),
+    ],
+    tblgen = "@llvm-project//mlir:mlir-tblgen",
+    td_file = "transforms/legalize_tensorlist.td",
+    deps = [":tensorflow_lite_patterns_td_files"],
+)
+
+cc_library(
+    name = "validators",
+    srcs = [
+        "utils/validators.cc",
+    ],
+    hdrs = [
+        "utils/validators.h",
+    ],
+    deps = [
+        "@llvm-project//mlir:Dialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+cc_library(
+    name = "stateful_error_reporter",
+    hdrs = ["stateful_error_reporter.h"],
+    compatible_with = get_compatible_with_portable(),
+    deps = ["//tensorflow/compiler/mlir/lite/core/api:error_reporter"],
+)
+
+gentbl_cc_library(
+    name = "tensorflow_lite_canonicalize_inc_gen",
+    compatible_with = get_compatible_with_portable(),
+    tbl_outs = [
+        (
+            ["-gen-rewriters"],
+            "ir/tfl_canonicalize.inc",
+        ),
+    ],
+    tblgen = "@llvm-project//mlir:mlir-tblgen",
+    td_file = "ir/tfl_canonicalize.td",
+    deps = [":tensorflow_lite_patterns_td_files"],
+)
+
+cc_library(
+    name = "utils",
+    hdrs = ["utils/utils.h"],
+    deps = [
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:Dialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+cc_library(
+    name = "attribute_utils",
+    srcs = ["utils/attribute_utils.cc"],
+    hdrs = ["utils/attribute_utils.h"],
+    deps = [
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+cc_library(
+    name = "pass_options",
+    hdrs = ["transforms/pass_options.h"],
+    compatible_with = get_compatible_with_portable(),
+    visibility = ["//visibility:public"],
+    deps = [
+        "@llvm-project//mlir:Pass",
+    ],
+)
+
+cc_library(
+    name = "pass",
+    hdrs = ["transforms/pass.h"],
+    compatible_with = get_compatible_with_portable(),
+    visibility = ["//visibility:public"],
+    deps = [
+        ":pass_options",
+        ":pass_options_setter",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+cc_library(
+    name = "pipeline",
+    hdrs = ["transforms/pipeline.h"],
+    compatible_with = get_compatible_with_portable(),
+    visibility = ["//visibility:public"],
+    deps = [
+        ":pass",
+        ":pass_options",
+        ":pass_options_setter",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+cc_library(
+    name = "pass_options_setter",
+    hdrs = ["transforms/pass_options_setter.h"],
+    compatible_with = get_compatible_with_portable(),
+    visibility = ["//visibility:public"],
+    deps = [
+        "@llvm-project//llvm:Support",
+    ],
+)
+
+cc_library(
+    name = "converter_pass_options_setter",
+    srcs = ["transforms/converter_pass_options_setter.cc"],
+    hdrs = ["transforms/converter_pass_options_setter.h"],
+    compatible_with = get_compatible_with_portable(),
+    visibility = ["//visibility:public"],
+    deps = [
+        ":common",
+        ":converter_flags_proto_cc",
+        ":optimize_pass_options",
+        ":pass_options",
+        ":pass_options_setter",
+        ":variable_freezing_pipeline_options",
+        "@llvm-project//llvm:Support",
+    ],
+)
+
+cc_library(
+    name = "tensorflow_lite_ops",
+    srcs = [
+        "ir/tfl_ops.cc",
+        "ir/tfl_ops.cc.inc",
+        "ir/tfl_ops.h.inc",
+        "ir/tfl_ops_attrdefs.h.inc",
+        "ir/tfl_ops_dialect.cc.inc",
+        "ir/tfl_ops_dialect.h.inc",
+        "ir/tfl_ops_enums.cc.inc",
+        "ir/tfl_ops_enums.h.inc",
+        "ir/tfl_ops_interface.cc.inc",
+        "ir/tfl_ops_interface.h.inc",
+        "runtime_verifiers.inc",
+    ],
+    hdrs = [
+        "ir/tfl_ops.h",
+    ],
+    deps = [
+        ":converter_inc",
+        ":cost_estimators",
+        ":size_utils",
+        ":tensorflow_lite_canonicalize_inc_gen",
+        ":tensorflow_lite_op_enums_inc_gen",
+        ":tensorflow_lite_op_interfaces_inc_gen",
+        ":tensorflow_lite_ops_inc_gen",
+        ":utils",
+        "//tensorflow/compiler/mlir/lite/quantization/ir:QuantOps",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:dynamic_shape_utils",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_op_interfaces",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_ops",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_traits",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "//tensorflow/core:framework",
+        "//tensorflow/core/platform:status",
+        "@com_google_absl//absl/container:flat_hash_map",
+        "@com_google_absl//absl/container:flat_hash_set",
+        "@com_google_absl//absl/status",
+        "@com_google_absl//absl/strings",
+        "@eigen_archive//:eigen3",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:ControlFlowInterfaces",
+        "@llvm-project//mlir:DerivedAttributeOpInterface",
+        "@llvm-project//mlir:Dialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:InferTypeOpInterface",
+        "@llvm-project//mlir:InliningUtils",
+        "@llvm-project//mlir:LoopLikeInterface",
+        "@llvm-project//mlir:QuantOps",
+        "@llvm-project//mlir:SideEffectInterfaces",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+    ],
+)
+
+cc_library(
+    name = "pass_registry_utils",
+    hdrs = ["transforms/pass_registry_utils.h"],
+    compatible_with = get_compatible_with_portable(),
+    visibility = ["//visibility:public"],
+    deps = [
+        ":pass_options",
+        ":pipeline",
+        "@llvm-project//mlir:Pass",
+    ],
+)
+
+cc_library(
+    name = "variable_freezing_pipeline_options",
+    hdrs = ["transforms/variable_freezing_pipeline_options.h"],
+    deps = [
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:Pass",
+    ],
+)
+
+cc_library(
+    name = "variable_freezing_pipeline",
+    srcs = ["transforms/variable_freezing_pipeline.cc"],
+    hdrs = ["transforms/variable_freezing_pipeline.h"],
+    compatible_with = get_compatible_with_portable(),
+    visibility = ["//visibility:public"],
+    deps = [
+        ":pass_registry_utils",
+        ":pipeline",
+        ":tensorflow_lite_tf_unfreeze_global_tensors",
+        ":variable_freezing_pipeline_options",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:tf_saved_model_passes",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+cc_library(
+    name = "tensorflow_lite",
+    srcs = [
+        "ir/tfl_canonicalize.inc",
+    ],
+    hdrs = [
+        "ir/tfl_ops.h",
+        "transforms/canonicalize_boundary_value_pass.h",
+        "transforms/optimize_batch_matmul_pass.h",
+        "transforms/optimize_broadcast_like_pass.h",
+        "transforms/optimize_pass.h",
+        "transforms/pass_registry_utils.h",
+        "transforms/passes.h",
+        "transforms/push_transpose_through_ewise_pass.h",
+        "transforms/tf_legalizations/analyze_variables_pass.h",
+        "transforms/tf_legalizations/legalize_tensorlist_pass.h",
+        "transforms/tf_legalizations/while_loop_outline_pass.h",
+        "transforms/tflite_passes/split_merged_operands_pass.h",
+        "transforms/tflite_passes/unfold_large_splat_constants_pass.h",
+        "transforms/unfreeze_global_constants.h",
+        "utils/attribute_utils.h",
+        "utils/utils.h",
+    ],
+    deps = [
+        ":attribute_utils",
+        ":canonicalize_boundary_value",
+        ":converter_inc",
+        ":cost_estimators",
+        ":optimize_broadcast_like_pass",
+        ":optimize_pass_options",
+        ":pass",
+        ":pass_options",
+        ":pass_registry_utils",
+        ":pipeline",
+        ":size_utils",
+        ":tensorflow_lite_canonicalize_inc_gen",
+        ":tensorflow_lite_legalize_tf_analyze_variables",
+        ":tensorflow_lite_legalize_tf_legalize_tensorlist",
+        ":tensorflow_lite_legalize_tf_while_loop_outline",
+        ":tensorflow_lite_op_enums_inc_gen",
+        ":tensorflow_lite_op_interfaces_inc_gen",
+        ":tensorflow_lite_ops",
+        ":tensorflow_lite_ops_inc_gen",
+        ":tensorflow_lite_optimize",
+        ":tensorflow_lite_passes_inc_gen",
+        ":tensorflow_lite_push_transpose_through_ewise_pass",
+        ":tensorflow_lite_split_merged_operands",
+        ":tensorflow_lite_tf_unfreeze_global_tensors",
+        ":tensorflow_lite_unfold_large_splat_constants",
+        "//tensorflow/compiler/mlir:op_or_arg_name_mapper",
+        "//tensorflow/compiler/mlir/lite/quantization/ir:QuantOps",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib:quantization_config",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:dynamic_shape_utils",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_op_interfaces",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_ops",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_traits",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "//tensorflow/core:framework",
+        "@com_google_absl//absl/container:flat_hash_map",
+        "@com_google_absl//absl/container:flat_hash_set",
+        "@com_google_absl//absl/strings",
+        "@eigen_archive//:eigen3",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:DerivedAttributeOpInterface",
+        "@llvm-project//mlir:Dialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:InferTypeOpInterface",
+        "@llvm-project//mlir:InliningUtils",
+        "@llvm-project//mlir:LoopLikeInterface",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:QuantOps",
+        "@llvm-project//mlir:SideEffectInterfaces",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+        "@stablehlo//:stablehlo_ops",
+    ],
+)
+
+cc_library(
+    name = "variables_utils",
+    srcs = [
+        "utils/variables_utils.cc",
+    ],
+    hdrs = [
+        "utils/variables_utils.h",
+    ],
+    deps = [
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:QuantOps",
+    ],
+)
+
+cc_library(
+    name = "size_utils",
+    srcs = [
+        "utils/size_utils.cc",
+    ],
+    hdrs = [
+        "utils/size_utils.h",
+    ],
+    deps = [
+        "@llvm-project//mlir:IR",
+    ],
+)
+
+cc_library(
+    name = "mlir_module_utils",
+    hdrs = ["utils/mlir_module_utils.h"],
+    deps = [
+        ":const_tensor_utils",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+tf_cc_test(
+    name = "size_utils_test",
+    size = "small",
+    srcs = ["utils/size_utils_test.cc"],
+    deps = [
+        ":size_utils",
+        "//tensorflow/core:test",
+        "//tensorflow/core:test_main",
+        "@llvm-project//mlir:IR",
+    ],
+)
+
+cc_library(
+    name = "cost_estimators",
+    hdrs = [
+        "utils/arithmetic_count_util.h",
+    ],
+    deps = [
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+cc_library(
+    name = "constant_utils",
+    srcs = [
+        "utils/constant_utils.cc",
+    ],
+    hdrs = [
+        "utils/constant_utils.h",
+    ],
+    deps = [
+        "//tensorflow/compiler/mlir/tensorflow:mangling_util",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_attributes",
+        "//tensorflow/core:protos_all_cc",
+        "//tensorflow/core/platform:status",
+        "@com_google_absl//absl/status",
+        "@com_google_absl//absl/status:statusor",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:BytecodeOpInterface",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+        "@local_tsl//tsl/platform:statusor",
+    ],
+)
+
+cc_library(
+    name = "low_bit_utils",
+    srcs = [
+        "utils/low_bit_utils.cc",
+    ],
+    hdrs = [
+        "utils/low_bit_utils.h",
+    ],
+)
+
+cc_library(
+    name = "lstm_utils",
+    srcs = [
+        "utils/lstm_utils.cc",
+    ],
+    hdrs = [
+        "utils/lstm_utils.h",
+    ],
+    deps = [
+        ":tensorflow_lite",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:dynamic_shape_utils",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TensorDialect",
+    ],
+)
+
+cc_library(
+    name = "fake_quant_utils",
+    srcs = [
+        "utils/fake_quant_utils.cc",
+    ],
+    hdrs = [
+        "utils/fake_quant_utils.h",
+    ],
+    deps = [
+        ":tensorflow_lite",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_ops",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+cc_library(
+    name = "nms_utils",
+    srcs = [
+        "utils/nms_utils.cc",
+    ],
+    hdrs = [
+        "utils/nms_utils.h",
+    ],
+    deps = [
+        ":tensorflow_lite",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_attributes",
+        "@flatbuffers",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+cc_library(
+    name = "tftext_utils",
+    srcs = [
+        "utils/tftext_utils.cc",
+    ],
+    hdrs = [
+        "utils/tftext_utils.h",
+    ],
+    deps = [
+        ":tensorflow_lite",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_attributes",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "//tensorflow/core:framework",
+        "//tensorflow/core/ir/types:Dialect",
+        "@flatbuffers",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+tf_cc_test(
+    name = "tftext_utils_test",
+    size = "small",
+    srcs = ["utils/tftext_utils_test.cc"],
+    deps = [
+        ":tftext_utils",
+        "//tensorflow/core:framework",
+        "//tensorflow/core:test",
+        "//tensorflow/core:test_main",
+        "@com_google_absl//absl/status",
+        "@local_tsl//tsl/platform:status",
+    ],
+)
+
+cc_library(
+    name = "perception_ops_utils",
+    srcs = [
+        "utils/perception_ops_utils.cc",
+    ],
+    hdrs = [
+        "utils/perception_ops_utils.h",
+    ],
+    deps = [
+        ":tensorflow_lite",
+        "//tensorflow/compiler/mlir/lite/core/c:tflite_common",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_attributes",
+        "@flatbuffers//:runtime_cc",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+cc_library(
+    name = "stateful_ops_utils",
+    srcs = [
+        "utils/stateful_ops_utils.cc",
+    ],
+    hdrs = [
+        "utils/stateful_ops_utils.h",
+    ],
+    deps = [
+        ":tensorflow_lite_ops",
+        ":utils",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+tf_cc_test(
+    name = "lstm_utils_test",
+    size = "small",
+    srcs = ["utils/lstm_utils_test.cc"],
+    deps = [
+        ":lstm_utils",
+        ":tensorflow_lite",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/core:test",
+        "//tensorflow/core:test_main",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TensorDialect",
+    ],
+)
+
+tf_cc_test(
+    name = "perception_ops_utils_test",
+    size = "small",
+    srcs = ["utils/perception_ops_utils_test.cc"],
+    deps = [
+        ":perception_ops_utils",
+        ":tensorflow_lite",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_attributes",
+        "//tensorflow/core:test",
+        "//tensorflow/core:test_main",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+cc_library(
+    name = "canonicalize_boundary_value",
+    srcs = [
+        "transforms/canonicalize_boundary_value_pass.cc",
+    ],
+    hdrs = [
+        "transforms/canonicalize_boundary_value_pass.h",
+    ],
+    deps = [
+        ":pass",
+        ":utils",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+        "@stablehlo//:stablehlo_ops",
+    ],
+)
+
+cc_library(
+    name = "tensorflow_lite_legalize_tf_analyze_variables",
+    srcs = [
+        "transforms/tf_legalizations/analyze_variables_pass.cc",
+    ],
+    hdrs = [
+        "transforms/tf_legalizations/analyze_variables_pass.h",
+    ],
+    deps = [
+        ":pass",
+        ":tensorflow_lite_ops",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+cc_library(
+    name = "tensorflow_lite_legalize_tf_legalize_tensorlist",
+    srcs = [
+        "transforms/tf_legalizations/legalize_tensorlist_pass.cc",
+    ],
+    hdrs = [
+        "transforms/tf_legalizations/legalize_tensorlist_pass.h",
+    ],
+    deps = [
+        ":convert_type",
+        ":pass",
+        ":tensorflow_lite_legalize_tensorlist_inc_gen",
+        ":tensorflow_lite_ops",
+        ":utils",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_ops",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+    ],
+)
+
+cc_library(
+    name = "tensorflow_lite_legalize_tf_while_loop_outline",
+    srcs = [
+        "transforms/tf_legalizations/while_loop_outline_pass.cc",
+    ],
+    hdrs = [
+        "transforms/tf_legalizations/while_loop_outline_pass.h",
+    ],
+    deps = [
+        ":pass",
+        ":tensorflow_lite_ops",
+        "//tensorflow/compiler/mlir:op_or_arg_name_mapper",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_ops",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+    ],
+)
+
+cc_library(
+    name = "tensorflow_lite_unfold_large_splat_constants",
+    srcs = [
+        "transforms/tflite_passes/unfold_large_splat_constants_pass.cc",
+    ],
+    hdrs = [
+        "transforms/tflite_passes/unfold_large_splat_constants_pass.h",
+    ],
+    deps = [
+        ":pass",
+        ":tensorflow_lite_ops",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:dynamic_shape_utils",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_ops",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+    ],
+)
+
+cc_library(
+    name = "tensorflow_lite_split_merged_operands",
+    srcs = [
+        "transforms/tflite_passes/split_merged_operands_pass.cc",
+    ],
+    hdrs = [
+        "transforms/tflite_passes/split_merged_operands_pass.h",
+    ],
+    deps = [
+        ":pass",
+        ":pass_options",
+        ":stateful_ops_utils",
+        ":tensorflow_lite_ops",
+        ":utils",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+cc_library(
+    name = "tensorflow_lite_legalize_tf",
+    srcs = [
+        "transforms/dilated_conv.cc",
+        "transforms/generated_legalize_tf.inc",
+        "transforms/generated_legalize_variables.inc",
+        "transforms/generated_lower_static_tensor_list.inc",
+        "transforms/generated_prepare_tf.inc",
+        "transforms/get_arithmetic_count.cc",
+        "transforms/if_outline.cc",
+        "transforms/insert_call_once_op.cc",
+        "transforms/legalize_hashtables.cc",
+        "transforms/legalize_jax_random.cc",
+        "transforms/legalize_tf.cc",
+        "transforms/legalize_tf_while.cc",
+        "transforms/legalize_variables.cc",
+        "transforms/lower_static_tensor_list.cc",
+        "transforms/optimize_functional_ops.cc",
+        "transforms/partitioned_topological_sort.cc",
+        "transforms/pin_ops_with_side_effects.cc",
+        "transforms/prepare_composite_functions_tf.cc",
+        "transforms/prepare_tf.cc",
+        "transforms/raise_custom_ops.cc",
+        "transforms/reduce_type_precision.cc",
+        "transforms/reduce_while_operands.cc",
+        "transforms/runtime_verify.cc",
+        "transforms/trim_functions_tf.cc",
+    ],
+    hdrs = [
+        "ir/tfl_ops_interface.h.inc",
+        "transforms/dilated_conv.h",
+        "transforms/passes.h",
+    ],
+    deps = [
+        ":attribute_utils",
+        ":constant_utils",
+        ":convert_type",
+        ":cost_estimators",
+        ":fake_quant_utils",
+        ":lstm_utils",
+        ":nms_utils",
+        ":perception_ops_utils",
+        ":size_utils",
+        ":stateful_ops_utils",
+        ":tensorflow_lite",
+        ":tensorflow_lite_legalize_tf_analyze_variables",
+        ":tensorflow_lite_legalize_tf_inc_gen",
+        ":tensorflow_lite_legalize_tf_legalize_tensorlist",
+        ":tensorflow_lite_legalize_variables_inc_gen",
+        ":tensorflow_lite_lower_static_tensor_list_inc_gen",
+        ":tensorflow_lite_passes_inc_gen",
+        ":tensorflow_lite_prepare_tf_inc_gen",
+        ":tensorflow_lite_tf_unfreeze_global_tensors",
+        ":tftext_utils",
+        ":validators",
+        ":variables_utils",
+        "//tensorflow/compiler/mlir:op_or_arg_name_mapper",
+        "//tensorflow/compiler/mlir/lite/quantization/ir:QuantOps",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs",
+        "//tensorflow/compiler/mlir/lite/stablehlo:legalize_tf",
+        "//tensorflow/compiler/mlir/lite/stablehlo:optimize_layout",
+        "//tensorflow/compiler/mlir/lite/stablehlo:prepare_hlo",
+        "//tensorflow/compiler/mlir/lite/stablehlo:tf_legalize_hlo",
+        "//tensorflow/compiler/mlir/lite/stablehlo:tfl_legalize_chlo",
+        "//tensorflow/compiler/mlir/lite/stablehlo:tfl_legalize_hlo",
+        "//tensorflow/compiler/mlir/quantization/common/ir:QuantOps",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib:quantization_config",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:convert_tensor",
+        "//tensorflow/compiler/mlir/tensorflow:dynamic_shape_utils",
+        "//tensorflow/compiler/mlir/tensorflow:error_util",
+        "//tensorflow/compiler/mlir/tensorflow:mangling_util",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_attributes",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_ops",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "//tensorflow/compiler/mlir/tensorflow:verification_utils",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:lower_tf_lib",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:tensorflow_passes",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:unroll_batch_matmul_pass",
+        "//tensorflow/compiler/mlir/tf2xla/transforms:xla_legalize_tf",
+        "//tensorflow/compiler/mlir/tf2xla/transforms:xla_legalize_tf_with_tf2xla",
+        "//tensorflow/core:framework",
+        "//tensorflow/core:lib",
+        "//tensorflow/core:protos_all_cc",
+        "//tensorflow/core/kernels:tensor_list",
+        "@com_google_absl//absl/algorithm:container",
+        "@com_google_absl//absl/container:flat_hash_set",
+        "@com_google_absl//absl/container:inlined_vector",
+        "@com_google_absl//absl/memory",
+        "@com_google_absl//absl/numeric:bits",
+        "@com_google_absl//absl/status",
+        "@com_google_absl//absl/status:statusor",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:AffineAnalysis",
+        "@llvm-project//mlir:Analysis",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:LoopLikeInterface",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:QuantOps",
+        "@llvm-project//mlir:SideEffectInterfaces",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+        "@llvm-project//mlir:Transforms",
+        "@local_xla//xla/mlir_hlo",
+        "@stablehlo//:stablehlo_ops",
+    ],
+)
+
+cc_library(
+    name = "tensorflow_lite_optimize",
+    srcs = [
+        "transforms/generated_optimize.inc",
+        "transforms/optimize_pass.cc",
+    ],
+    hdrs = [
+        "transforms/optimize_pass.h",
+    ],
+    deps = [
+        ":attribute_utils",
+        ":constant_utils",
+        ":convert_type",
+        ":optimize_pass_options",
+        ":pass",
+        ":tensorflow_lite_ops",
+        ":tensorflow_lite_optimize_inc_gen",
+        ":utils",
+        ":validators",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib:quantization_config",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:dynamic_shape_utils",
+        "//tensorflow/compiler/mlir/tensorflow:verification_utils",
+        "@com_google_absl//absl/container:flat_hash_set",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+    ],
+)
+
+cc_library(
+    name = "tensorflow_lite_optimize_batch_matmul",
+    srcs = [
+        "transforms/generated_optimize_batch_matmul.inc",
+        "transforms/optimize_batch_matmul_pass.cc",
+    ],
+    hdrs = [
+        "transforms/optimize_batch_matmul_pass.h",
+    ],
+    deps = [
+        ":convert_type",
+        ":pass",
+        ":pass_options",
+        ":tensorflow_lite_ops",
+        ":tensorflow_lite_optimize_batch_matmul_inc_gen",
+        ":tensorflow_lite_passes_inc_gen",
+        ":utils",
+        ":validators",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib:quantization_config",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:dynamic_shape_utils",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "//tensorflow/compiler/mlir/tensorflow:verification_utils",
+        "@com_google_absl//absl/container:flat_hash_set",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+    ],
+)
+
+cc_library(
+    name = "optimize_broadcast_like_pass",
+    srcs = [
+        "transforms/optimize_broadcast_like_pass.cc",
+    ],
+    hdrs = [
+        "transforms/optimize_broadcast_like_pass.h",
+    ],
+    deps = [
+        ":optimize_broadcast_like_inc_gen",
+        ":pass",
+        ":pass_options",
+        ":tensorflow_lite_ops",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:Dialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+    ],
+)
+
+cc_library(
+    name = "tensorflow_lite_push_transpose_through_ewise_pass",
+    srcs = [
+        "transforms/push_transpose_through_ewise_pass.cc",
+    ],
+    hdrs = [
+        "transforms/push_transpose_through_ewise_pass.h",
+    ],
+    deps = [
+        ":pass",
+        ":tensorflow_lite_ops",
+        ":utils",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+    ],
+)
+
+cc_library(
+    name = "tensorflow_lite_tf_unfreeze_global_tensors",
+    srcs = [
+        "transforms/unfreeze_global_constants.cc",
+    ],
+    hdrs = [
+        "transforms/unfreeze_global_constants.h",
+    ],
+    deps = [
+        ":pass",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_ops",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+cc_library(
+    name = "tensorflow_lite_quantize",
+    srcs = [
+        "transforms/decompose_hybrid_quantization.cc",
+        "transforms/default_quant_params.cc",
+        "transforms/generated_post_quantize.inc",
+        "transforms/generated_quantize.inc",
+        "transforms/lower_quant_annotations_helper.cc",
+        "transforms/lower_quant_annotations_pass.cc",
+        "transforms/modify_io_nodes.cc",
+        "transforms/optimize_op_order.cc",
+        "transforms/post_quantize.cc",
+        "transforms/prepare_quantize.cc",
+        "transforms/prepare_quantize_dynamic_range.cc",
+        "transforms/prepare_quantize_helper.cc",
+        "transforms/quantize.cc",
+        "transforms/quantize_variables.cc",
+        "utils/generated_op_quant_spec_getters.inc",
+    ],
+    hdrs = [
+        "transforms/lower_quant_annotations_helper.h",
+        "transforms/passes.h",
+        "transforms/prepare_quantize_helper.h",
+    ],
+    deps = [
+        "convert_type",
+        ":op_quant_spec_getters_inc",
+        ":stateful_ops_utils",
+        ":tensorflow_lite",
+        ":tensorflow_lite_passes_inc_gen",
+        ":tensorflow_lite_post_quantize_inc_gen",
+        ":tensorflow_lite_quantize_by_converter_inc_gen",
+        ":tensorflow_lite_quantize_inc_gen",
+        ":validators",
+        "//tensorflow/compiler/mlir/lite/quantization/ir:QuantOps",
+        "//tensorflow/compiler/mlir/lite/quantization/lite:tfl_to_std",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs",
+        "//tensorflow/compiler/mlir/lite/tools/optimize:operator_property",
+        "//tensorflow/compiler/mlir/quantization/common:uniform_quantized_types",
+        "//tensorflow/compiler/mlir/quantization/common/ir:QuantOps",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib:quantization_config",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "//tensorflow/core:lib",
+        "//tensorflow/core:protos_all_cc",
+        "//tensorflow/core/platform:logging",
+        "@com_google_absl//absl/container:flat_hash_set",
+        "@com_google_absl//absl/memory",
+        "@com_google_absl//absl/strings",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:QuantOps",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+        "@local_xla//xla/mlir_hlo",
+        "@stablehlo//:stablehlo_ops",
+    ],
+)
+
+cc_library(
+    name = "tensorflow_lite_d2s",
+    srcs = [
+        "transforms/dense_to_sparse_pass.cc",
+    ],
+    hdrs = [
+        "transforms/dense_to_sparse_pass.h",
+    ],
+    deps = [
+        ":pass",
+        ":pass_options",
+        ":tensorflow_lite_ops",
+        "//tensorflow/compiler/mlir/lite/kernels/internal/utils:sparsity_format_converter",
+        "@com_google_absl//absl/memory",
+        "@eigen_archive//:eigen3",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+cc_library(
+    name = "lift_tflite_flex_ops",
+    srcs = [
+        "transforms/lift_tflite_flex_ops.cc",
+    ],
+    hdrs = [
+        "transforms/lift_tflite_flex_ops.h",
+    ],
+    deps = [
+        ":tensorflow_lite",
+        ":tensorflow_lite_passes_inc_gen",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:convert_attr",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_attributes",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_ops",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "//tensorflow/core:framework",
+        "//tensorflow/core:lib",
+        "//tensorflow/core:protos_all_cc",
+        "@com_google_absl//absl/strings",
+        "@flatbuffers",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+    ],
+)
+
+filegroup(
+    name = "generated_op_quant_spec_getters",
+    srcs = [
+        "utils/generated_op_quant_spec_getters.inc",
+    ],
+)
+
+gentbl_cc_library(
+    name = "op_quant_spec_getters_inc",
+    compatible_with = get_compatible_with_portable(),
+    tbl_outs = [([], "utils/generated_op_quant_spec_getters.inc")],
+    tblgen = "//tensorflow/compiler/mlir/lite/quantization:op_quant_spec_getters_gen",
+    td_file = "ir/tfl_ops.td",
+    deps = [
+        ":tensorflow_lite_ops_td_files",
+    ],
+)
+
+gentbl_cc_library(
+    name = "tflite_op_coverage_spec_inc",
+    compatible_with = get_compatible_with_portable(),
+    tbl_outs = [([], "utils/tflite_op_coverage_spec.inc")],
+    tblgen = "//tensorflow/compiler/mlir/lite/quantization:tflite_op_coverage_spec_getters_gen",
+    td_file = "ir/tfl_ops.td",
+    visibility = ["//learning/brain/mobile/model_optimization/g3doc/autogen:__pkg__"],
+    deps = [
+        ":tensorflow_lite_ops_td_files",
+    ],
+)
+
+tf_native_cc_binary(
+    name = "converter-gen",
+    srcs = [
+        "converter_gen.cc",
+    ],
+    compatible_with = get_compatible_with_portable(),
+    deps = [
+        "@llvm-project//llvm:Support",
+        "@llvm-project//llvm:TableGen",
+        "@llvm-project//mlir:TableGen",
+    ],
+)
+
+gentbl_cc_library(
+    name = "converter_inc",
+    compatible_with = get_compatible_with_portable(),
+    tbl_outs = [
+        (
+            ["--gen-operator-converters"],
+            "operator_converters.inc",
+        ),
+        (
+            ["--gen-runtime-verifiers"],
+            "runtime_verifiers.inc",
+        ),
+    ],
+    tblgen = ":converter-gen",
+    td_file = "ir/tfl_ops.td",
+    test = 1,
+    deps = [
+        ":tensorflow_lite_ops_td_files",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib:quantization_td_files",
+    ],
+)
+
+cc_library(
+    name = "flatbuffer_tflite_operator_lib",
+    srcs = [
+        "flatbuffer_operator.cc",
+        "operator_converters.inc",
+    ],
+    hdrs = [
+        "flatbuffer_operator.h",
+    ],
+    deps = [
+        ":convert_type",
+        ":converter_inc",
+        ":tensorflow_lite",
+        "//tensorflow/compiler/mlir/lite/core/c:tflite_common",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs_with_mutable",
+        "//tensorflow/compiler/mlir/lite/schema:schema_utils",
+        "//tensorflow/compiler/mlir/tensorflow:dynamic_shape_utils",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "//tensorflow/core/platform:errors",
+        "//tensorflow/core/platform:status",
+        "//tensorflow/core/platform:statusor",
+        "@com_google_absl//absl/container:flat_hash_map",
+        "@com_google_absl//absl/status:statusor",
+        "@com_google_absl//absl/strings",
+        "@flatbuffers",
+        "@llvm-project//llvm:Analysis",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+        "@local_tsl//tsl/platform:status",
+        "@stablehlo//:stablehlo_ops",
+        "@stablehlo//:vhlo_ops",
+        "@stablehlo//:vhlo_types",
+    ],
+)
+
+tf_native_cc_binary(
+    name = "flatbuffer_to_string",
+    srcs = ["flatbuffer_to_string.cc"],
+    deps = [
+        "//tensorflow/compiler/mlir/lite/core:absl_error_model_builder",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs_with_reflection",
+        "@flatbuffers",
+    ],
+)
+
+tf_native_cc_binary(
+    name = "json_to_flatbuffer",
+    srcs = ["json_to_flatbuffer.cc"],
+    deps = [
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs",
+        "@flatbuffers",
+    ],
+)
+
+cc_library(
+    name = "flatbuffer_export",
+    srcs = [
+        "flatbuffer_export.cc",
+    ],
+    hdrs = [
+        "flatbuffer_export.h",
+        "flatbuffer_export_flags.h",
+    ],
+    deps = [
+        ":control_edges",
+        ":convert_type",
+        ":converter_flags_proto_cc",
+        ":flatbuffer_tflite_operator_lib",
+        ":lite_version",
+        ":low_bit_utils",
+        ":mlir_module_utils",
+        ":region_isolation",
+        ":stateful_ops_utils",
+        ":string_utils",
+        ":tensorflow_lite",
+        "//tensorflow/compiler/mlir:op_or_arg_name_mapper",
+        "//tensorflow/compiler/mlir/lite/core:macros",
+        "//tensorflow/compiler/mlir/lite/core/c:tflite_common",
+        "//tensorflow/compiler/mlir/lite/delegates/flex:allowlisted_flex_ops_lib",
+        "//tensorflow/compiler/mlir/lite/experimental/remat:metadata_util",
+        "//tensorflow/compiler/mlir/lite/metrics:converter_error_data_proto_cc",
+        "//tensorflow/compiler/mlir/lite/metrics:error_collector_inst",
+        "//tensorflow/compiler/mlir/lite/quantization/ir:QuantOps",
+        "//tensorflow/compiler/mlir/lite/schema:debug_metadata_fbs_with_mutable",
+        "//tensorflow/compiler/mlir/lite/schema:schema_conversion_utils",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs_with_mutable",
+        "//tensorflow/compiler/mlir/lite/tools/versioning",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:convert_tensor",
+        "//tensorflow/compiler/mlir/tensorflow:dynamic_shape_utils",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "//tensorflow/compiler/mlir/tensorflow:translate_utils",
+        "//tensorflow/core:framework",
+        "//tensorflow/core:portable_gif_internal",
+        "//tensorflow/core:protos_all_cc",
+        "@com_google_absl//absl/algorithm:container",
+        "@com_google_absl//absl/base:core_headers",
+        "@com_google_absl//absl/container:flat_hash_map",
+        "@com_google_absl//absl/container:flat_hash_set",
+        "@com_google_absl//absl/log",
+        "@com_google_absl//absl/status",
+        "@com_google_absl//absl/strings",
+        "@com_google_absl//absl/strings:str_format",
+        "@flatbuffers",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:QuantOps",
+        "@llvm-project//mlir:Support",
+        "@local_tsl//tsl/platform:fingerprint",
+        "@local_tsl//tsl/platform:tstring",
+        "@stablehlo//:stablehlo_ops",
+        "@stablehlo//:vhlo_ops",
+    ],
+)
+
+cc_library(
+    name = "flatbuffer_import",
+    srcs = [
+        "flatbuffer_import.cc",
+    ],
+    hdrs = [
+        "flatbuffer_import.h",
+    ],
+    deps = [
+        ":const_tensor_utils",
+        ":control_edges",
+        ":convert_type",
+        ":flatbuffer_tflite_operator_lib",
+        ":offset_buffer",
+        ":size_utils",
+        ":tensorflow_lite",
+        "//tensorflow/compiler/mlir/lite/core:absl_error_model_builder",
+        "//tensorflow/compiler/mlir/lite/experimental/remat:metadata_util",
+        "//tensorflow/compiler/mlir/lite/quantization/ir:QuantOps",
+        "//tensorflow/compiler/mlir/lite/schema:debug_metadata_fbs_with_mutable",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs_with_mutable",
+        "//tensorflow/compiler/mlir/lite/schema:schema_utils",
+        "//tensorflow/compiler/mlir/lite/stablehlo:legalize_stablehlo_composite_to_tfl_custom",
+        "//tensorflow/compiler/mlir/lite/stablehlo:legalize_stablehlo_to_vhlo_pass",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:convert_tensor",
+        "//tensorflow/compiler/mlir/tensorflow:dynamic_shape_utils",
+        "//tensorflow/compiler/mlir/tensorflow:mangling_util",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_attributes",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "//tensorflow/core:protos_all_cc",
+        "//tensorflow/core/platform:errors",
+        "@com_google_absl//absl/container:flat_hash_map",
+        "@com_google_absl//absl/container:flat_hash_set",
+        "@com_google_absl//absl/log",
+        "@com_google_absl//absl/status",
+        "@com_google_absl//absl/status:statusor",
+        "@com_google_absl//absl/strings",
+        "@llvm-project//llvm:Analysis",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:FuncExtensions",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:QuantOps",
+        "@llvm-project//mlir:ReconcileUnrealizedCasts",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TranslateLib",
+        "@local_tsl//tsl/platform:errors",
+        "@local_tsl//tsl/platform:status",
+        "@local_tsl//tsl/platform:statusor",
+        "@stablehlo//:stablehlo_ops",
+        "@stablehlo//:vhlo_ops",
+    ],
+)
+
+cc_library(
+    name = "convert_type",
+    srcs = [
+        "utils/convert_type.cc",
+    ],
+    hdrs = [
+        "utils/convert_type.h",
+    ],
+    deps = [
+        ":tensorflow_lite_ops",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "//tensorflow/core:protos_all_cc",
+        "//tensorflow/core/platform:errors",
+        "@com_google_absl//absl/status:statusor",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+    ],
+)
+
+cc_library(
+    name = "region_isolation",
+    srcs = [
+        "utils/region_isolation.cc",
+    ],
+    hdrs = [
+        "utils/region_isolation.h",
+    ],
+    deps = [
+        "@com_google_absl//absl/strings:str_format",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+    ],
+)
+
+tf_cc_test(
+    name = "region_isolation_test",
+    srcs = [
+        "utils/region_isolation_test.cc",
+    ],
+    deps = [
+        ":region_isolation",
+        "@com_google_googletest//:gtest_main",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:TransformUtils",
+        "@stablehlo//:stablehlo_ops",
+    ],
+)
+
+cc_library(
+    name = "optimize_pass_options",
+    hdrs = ["transforms/optimize_pass_options.h"],
+    deps = [
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:Pass",
+    ],
+)
+
+cc_library(
+    name = "flatbuffer_translate_lib",
+    hdrs = [
+        "flatbuffer_export.h",
+        "flatbuffer_export_flags.h",
+        "flatbuffer_import.h",
+        "utils/convert_type.h",
+    ],
+    deps = [
+        ":converter_flags_proto_cc",
+        ":flatbuffer_export",
+        ":flatbuffer_import",
+        "//tensorflow/compiler/mlir:op_or_arg_name_mapper",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs",
+        "//tensorflow/core:protos_all_cc",
+        "@com_google_absl//absl/status:statusor",
+        "@com_google_absl//absl/strings",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+    ],
+)
+
+cc_library(
+    name = "flatbuffer_translate_registration",
+    srcs = [
+        "flatbuffer_translate.cc",
+    ],
+    deps = [
+        ":flatbuffer_translate_lib",
+        ":tensorflow_lite",
+        "//tensorflow/compiler/mlir/lite/quantization/ir:QuantOps",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:mlir_roundtrip_flags",
+        "//tensorflow/compiler/mlir/tensorflow/translate/tools:parsers",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:MlirTranslateMain",
+        "@llvm-project//mlir:QuantOps",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TranslateLib",
+        "@stablehlo//:stablehlo_ops",
+        "@stablehlo//:vhlo_ops",
+    ],
+    alwayslink = 1,
+)
+
+tf_cc_binary(
+    name = "flatbuffer_translate",
+    deps = [
+        ":flatbuffer_translate_registration",
+    ],
+)
+
+cc_library(
+    name = "tf_tfl_translate_cl_options",
+    srcs = [
+        "tf_tfl_translate_cl.cc",
+    ],
+    hdrs = [
+        "tf_tfl_translate_cl.h",
+    ],
+    deps = [
+        "@llvm-project//llvm:Support",
+    ],
+    alwayslink = 1,
+)
+
+cc_library(
+    name = "common",
+    hdrs = [
+        "common/tfl_pass_config.h",
+    ],
+    deps = [
+        "//tensorflow/compiler/mlir/lite:converter_flags_proto_cc",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib:quantization_config",
+        "@com_google_absl//absl/strings",
+        "@llvm-project//llvm:Support",
+    ],
+)
+
+filegroup(
+    name = "tf_tfl_translate_main",
+    srcs = [
+        "tf_tfl_translate.cc",
+    ],
+)
+
+tf_cc_binary(
+    name = "tf_tfl_translate",
+    srcs = [
+        ":tf_tfl_translate_main",
+    ],
+    deps = [
+        ":common",
+        ":flatbuffer_translate_lib",
+        ":flatbuffer_translate_registration",
+        ":tensorflow_lite",
+        ":tf_tfl_translate_cl_options",
+        ":tf_to_tfl_flatbuffer",
+        "//tensorflow/compiler/mlir:init_mlir",
+        "//tensorflow/compiler/mlir/lite:converter_flags_proto_cc",
+        "//tensorflow/compiler/mlir/lite/tools:translate_cl_options",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib:quantization_config",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:mlir_roundtrip_flags",
+        "//tensorflow/compiler/tf2xla/kernels:xla_ops",
+        "//tensorflow/core:core_cpu_base",
+        "//tensorflow/core:protos_all_cc",
+        "//tensorflow/core/platform:errors",
+        "@com_google_absl//absl/status:statusor",
+        "@com_google_absl//absl/strings",
+        "@com_google_absl//absl/types:span",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:FuncExtensions",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Parser",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:Support",
+        "@local_xla//xla/hlo/translate/hlo_to_mhlo:translate",
+        "@local_xla//xla/mlir_hlo",
+        "@stablehlo//:stablehlo_ops",
+    ],
+)
+
+cc_library(
+    name = "tf_tfl_passes",
+    srcs = ["tf_tfl_passes.cc"],
+    hdrs = [
+        "tf_tfl_passes.h",
+    ],
+    deps = [
+        ":common",
+        ":converter_flags_proto_cc",
+        ":converter_pass_options_setter",
+        ":fake_quant_utils",
+        ":optimize_broadcast_like_pass",
+        ":pass",
+        ":pass_registry_utils",
+        ":tensorflow_lite_d2s",  # buildcleaner: keep
+        ":tensorflow_lite_legalize_tf",  # buildcleaner: keep
+        ":tensorflow_lite_optimize",  # buildcleaner: keep
+        ":tensorflow_lite_optimize_batch_matmul",  # buildcleaner: keep
+        ":tensorflow_lite_push_transpose_through_ewise_pass",  # buildcleaner: keep
+        ":tensorflow_lite_quantize",  # buildcleaner: keep
+        ":tensorflow_lite_tf_unfreeze_global_tensors",
+        ":variable_freezing_pipeline",
+        "//tensorflow/compiler/mlir/lite/core:macros",
+        "//tensorflow/compiler/mlir/lite/quantization:quantization_passes",
+        "//tensorflow/compiler/mlir/lite/quantization/tensorflow:tf_quantization_passes",
+        "//tensorflow/compiler/mlir/lite/stablehlo:build_stablehlo_composite",
+        "//tensorflow/compiler/mlir/lite/stablehlo:compose_uniform_quantized_type_pass",
+        "//tensorflow/compiler/mlir/lite/stablehlo:composite_lowering",
+        "//tensorflow/compiler/mlir/lite/stablehlo:legalize_qdq_custom_call",
+        "//tensorflow/compiler/mlir/lite/stablehlo:legalize_stablehlo_composite_to_tfl_custom",
+        "//tensorflow/compiler/mlir/lite/stablehlo:legalize_tf_xla_call_module_to_stablehlo_pass",
+        "//tensorflow/compiler/mlir/lite/stablehlo:lift_callsite_loc_caller",
+        "//tensorflow/compiler/mlir/lite/stablehlo:prepare_hlo",  # buildcleaner: keep
+        "//tensorflow/compiler/mlir/lite/stablehlo:rename_entrypoint_to_main",
+        "//tensorflow/compiler/mlir/lite/stablehlo:tf_legalize_hlo",  # buildcleaner: keep
+        "//tensorflow/compiler/mlir/lite/stablehlo:tfl_legalize_chlo",  # buildcleaner: keep
+        "//tensorflow/compiler/mlir/lite/stablehlo:tfl_legalize_hlo",  # buildcleaner: keep
+        "//tensorflow/compiler/mlir/lite/stablehlo:transforms",
+        "//tensorflow/compiler/mlir/lite/stablehlo:uniform_quantized_stablehlo_to_tfl_pass",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib:quantization_config",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:tensorflow_passes",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:tf_saved_model_passes",
+        "//tensorflow/core:core_cpu_base",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:Transforms",
+        "@local_xla//xla/mlir_hlo:mhlo_passes",
+        "@local_xla//xla/mlir_hlo:stablehlo_extension_passes",
+        "@stablehlo//:stablehlo_passes",
+    ],
+)
+
+cc_library(
+    name = "tf_to_tfl_flatbuffer",
+    srcs = ["tf_to_tfl_flatbuffer.cc"],
+    hdrs = [
+        "tf_to_tfl_flatbuffer.h",
+    ],
+    deps = [
+        ":common",
+        ":converter_flags_proto_cc",
+        ":flatbuffer_translate_lib",
+        ":mlir_module_utils",
+        ":tensorflow_lite",
+        ":tf_tfl_passes",
+        "//tensorflow/cc/saved_model:loader",
+        "//tensorflow/compiler/mlir:op_or_arg_name_mapper",
+        "//tensorflow/compiler/mlir/lite/core:macros",
+        "//tensorflow/compiler/mlir/lite/debug",
+        "//tensorflow/compiler/mlir/lite/experimental/remat:metadata_util",
+        "//tensorflow/compiler/mlir/lite/metrics:converter_error_data_proto_cc",
+        "//tensorflow/compiler/mlir/lite/metrics:error_collector_inst",
+        "//tensorflow/compiler/mlir/lite/quantization/lite/toco_legacy:quantize_weights",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs",
+        "//tensorflow/compiler/mlir/lite/stablehlo:legalize_stablehlo_composite_to_tfl_custom",
+        "//tensorflow/compiler/mlir/lite/stablehlo:legalize_stablehlo_to_vhlo_pass",
+        "//tensorflow/compiler/mlir/lite/stablehlo:op_stat_pass",
+        "//tensorflow/compiler/mlir/lite/stablehlo:stablehlo_util",
+        "//tensorflow/compiler/mlir/lite/stablehlo:transforms",
+        "//tensorflow/compiler/mlir/lite/tools/optimize:reduced_precision_metadata",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib:quantization_config",
+        "//tensorflow/compiler/mlir/quantization/stablehlo:quantization_config_proto_cc",
+        "//tensorflow/compiler/mlir/quantization/stablehlo:quantize_passes",
+        "//tensorflow/compiler/mlir/quantization/tensorflow:quantization_options_proto_cc",
+        "//tensorflow/compiler/mlir/quantization/tensorflow:quantize_passes",
+        "//tensorflow/compiler/mlir/quantization/tensorflow:quantize_preprocess",
+        "//tensorflow/compiler/mlir/quantization/tensorflow/python:py_function_lib",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:error_util",
+        "//tensorflow/compiler/mlir/tensorflow:file_tf_mlir_translate",
+        "//tensorflow/compiler/mlir/tensorflow:mlir_import_options",
+        "//tensorflow/compiler/mlir/tensorflow:mlir_roundtrip_flags",
+        "//tensorflow/compiler/mlir/tensorflow:tf_dialect_lib",
+        "//tensorflow/compiler/mlir/tensorflow:translate_lib",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:tf_dialect_passes",
+        "//tensorflow/core:core_cpu_base",
+        "//tensorflow/core:framework",
+        "//tensorflow/core:protos_all_cc",
+        "//tensorflow/core/ir/types:Dialect",
+        "//tensorflow/core/platform:status",
+        "@com_google_absl//absl/log",
+        "@com_google_absl//absl/status",
+        "@com_google_absl//absl/status:statusor",
+        "@com_google_absl//absl/strings",
+        "@com_google_absl//absl/types:span",
+        "@flatbuffers//:runtime_cc",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:BytecodeWriter",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:FuncExtensions",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:Parser",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:QuantOps",
+        "@llvm-project//mlir:ReconcileUnrealizedCasts",
+        "@llvm-project//mlir:Support",
+        "@local_tsl//tsl/platform:protobuf",
+        "@stablehlo//:stablehlo_ops",
+        "@stablehlo//:vhlo_ops",
+    ],
+)
+
+cc_library(
+    name = "offset_buffer",
+    hdrs = ["offset_buffer.h"],
+)
+
+cc_library(
+    name = "const_tensor_utils",
+    srcs = ["utils/const_tensor_utils.cc"],
+    hdrs = ["utils/const_tensor_utils.h"],
+    deps = [
+        ":convert_type",
+        ":low_bit_utils",
+        ":string_utils",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs",
+        "//tensorflow/compiler/mlir/tensorflow:dynamic_shape_utils",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "//tensorflow/core:protos_all_cc",
+        "@com_google_absl//absl/base",
+        "@com_google_absl//absl/base:core_headers",
+        "@com_google_absl//absl/meta:type_traits",
+        "@com_google_absl//absl/status",
+        "@com_google_absl//absl/status:statusor",
+        "@com_google_absl//absl/strings",
+        "@eigen_archive//:eigen3",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:QuantOps",
+        "@llvm-project//mlir:Support",
+        "@local_tsl//tsl/platform:statusor",
+    ],
+)
+
+cc_library(
+    name = "string_utils",
+    srcs = ["utils/string_utils.cc"],
+    hdrs = ["utils/string_utils.h"],
+    visibility = ["//visibility:public"],
+)
+
+exports_files(srcs = ["allocation.h"])
+
+cc_library(
+    name = "allocation",
+    srcs = [
+        "allocation.cc",
+    ] + select({
+        ":tflite_mmap_disabled": [
+            "mmap_allocation_disabled.cc",
+        ],
+        "//conditions:default": [
+            "mmap_allocation.cc",
+        ],
+    }),
+    hdrs = [
+        "allocation.h",
+    ],
+    compatible_with = get_compatible_with_portable(),
+    copts = tflite_copts_warnings(),
+    visibility = ["//visibility:public"],
+    deps = ["//tensorflow/compiler/mlir/lite/core/api:error_reporter"],
+)
+
+exports_files(srcs = ["utils/control_edges.h"])
+
+cc_library(
+    name = "control_edges",
+    hdrs = ["utils/control_edges.h"],
+    visibility = ["//tensorflow/compiler/mlir/lite/experimental/remat:__pkg__"],
+)
+
+tf_cc_test(
+    name = "offset_buffer_test",
+    srcs = ["offset_buffer_test.cc"],
+    deps = [
+        ":offset_buffer",
+        "//tensorflow/core:test",
+        "//tensorflow/core:test_main",
+    ],
+)
+
+build_test(
+    name = "tensorflow_lite_build_test",
+    targets = [
+        ":tensorflow_lite",
+    ],
+)
+
+# LINT.IfChange
+
+bool_flag(
+    name = "enable_fuchsia_mmap",
+    build_setting_default = True,
+)
+
+config_setting(
+    name = "tflite_with_xnnpack_explicit_false",
+    define_values = {"tflite_with_xnnpack": "false"},
+)
+
+# A config for enabling tensorflow profiler in TFLite. Currently, it only supports dynamic
+# allocation. Add '--define=tflite_tensorflow_profiler=true' in your build command line to use it.
+config_setting(
+    name = "tensorflow_profiler_config",
+    define_values = {"tflite_tensorflow_profiler": "true"},
+)
+
+config_setting(
+    name = "fuchsia_mmap_disabled",
+    constraint_values = if_google(
+        ["//third_party/bazel_platforms/os:fuchsia"],
+        [],
+    ),
+    flag_values = {
+        ":enable_fuchsia_mmap": "False",
+    },
+    values = if_oss(
+        # TODO(b/149248802) When we have a Fuchsia Bazel SDK update to use the values it sets.
+        {"cpu": "fuchsia"},
+        {},
+    ),
+)
+
+config_setting(
+    name = "tflite_mmap_disabled_true",
+    values = {
+        "copt": "-DTFLITE_MMAP_DISABLED",
+    },
+)
+
+selects.config_setting_group(
+    name = "tflite_mmap_disabled",
+    match_any = [
+        ":fuchsia_mmap_disabled",
+        ":tflite_mmap_disabled_true",
+        "//tensorflow:windows",
+    ],
+)
+# LINT.ThenChange(//tensorflow/lite/BUILD)
+
+# LINT.IfChange(version)
+cc_library(
+    name = "lite_version",
+    hdrs = ["version.h"],
+    compatible_with = get_compatible_with_portable(),
+    copts = tflite_copts_warnings(),
+)
+# LINT.ThenChange(//tensorflow/lite:version)
+
+# OSS only: This target is header-only. Link `types_proto_cc_impl` only to
+# `libtensorflow_framework.so` via `lib_internal_impl`. Do NOT link `types_flags_proto_cc_impl`
+# directly unless the target does not link `libtensorflow_framework.so`.
+tf_proto_library(
+    name = "types_proto",
+    srcs = ["types.proto"],
+    make_default_target_header_only = True,
+    visibility = ["//visibility:public"],
+)
+
+# OSS only: This target is header-only. Link `converter_flags_proto_cc_impl` only to
+# `libtensorflow_framework.so` via `lib_internal_impl`. Do NOT link `converter_flags_proto_cc_impl`
+# directly unless the target does not link `libtensorflow_framework.so`.
+tf_proto_library(
+    name = "converter_flags_proto",
+    srcs = ["converter_flags.proto"],
+    make_default_target_header_only = True,
+    protodeps = [
+        "//tensorflow/compiler/mlir/quantization/stablehlo:quantization_options_proto",
+        "//tensorflow/compiler/mlir/quantization/stablehlo:quantization_config_proto",
+        "//tensorflow/compiler/mlir/lite/debug:debug_options_proto",
+        ":types_proto",
+    ],
+    visibility = ["//visibility:public"],
+)
+
+tf_proto_library(
+    name = "model_flags_proto",
+    srcs = ["model_flags.proto"],
+    make_default_target_header_only = True,
+    protodeps = [":types_proto"],
+    visibility = ["//visibility:public"],
+)
+
+# copybara:uncomment_begin(google-only)
+# py_proto_library(
+#     name = "types_py_proto",
+#     visibility = ["//visibility:public"],
+#     deps = [":types_proto"],
+# )
+#
+# py_proto_library(
+#     name = "model_flags_py_proto",
+#     visibility = ["//visibility:public"],
+#     deps = [":model_flags_proto"],
+# )
+#
+# py_proto_library(
+#     name = "converter_flags_py_proto",
+#     visibility = ["//visibility:public"],
+#     deps = [":converter_flags_proto"],
+# )
+# copybara:uncomment_end
+
+cc_library(
+    name = "dequant_split",
+    srcs = [
+        "DequantSplit.cc",
+    ],
+    hdrs = [
+        "DequantSplit.h",
+    ],
+    deps = [
+        ":attribute_utils",
+        ":constant_utils",
+        ":convert_type",
+        ":cost_estimators",
+        ":fake_quant_utils",
+        ":lstm_utils",
+        ":nms_utils",
+        ":perception_ops_utils",
+        ":size_utils",
+        ":stateful_ops_utils",
+        ":tensorflow_lite",
+        ":tensorflow_lite_legalize_tf_analyze_variables",
+        ":tensorflow_lite_legalize_tf_inc_gen",
+        ":tensorflow_lite_legalize_tf_legalize_tensorlist",
+        ":tensorflow_lite_legalize_variables_inc_gen",
+        ":tensorflow_lite_lower_static_tensor_list_inc_gen",
+        ":tensorflow_lite_passes_inc_gen",
+        ":tensorflow_lite_prepare_tf_inc_gen",
+        ":tensorflow_lite_tf_unfreeze_global_tensors",
+        ":tftext_utils",
+        ":validators",
+        ":variables_utils",
+        "//tensorflow/compiler/mlir:op_or_arg_name_mapper",
+        "//tensorflow/compiler/mlir/lite/quantization/ir:QuantOps",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs",
+        "//tensorflow/compiler/mlir/lite/stablehlo:legalize_tf",
+        "//tensorflow/compiler/mlir/lite/stablehlo:optimize_layout",
+        "//tensorflow/compiler/mlir/lite/stablehlo:prepare_hlo",
+        "//tensorflow/compiler/mlir/lite/stablehlo:tf_legalize_hlo",
+        "//tensorflow/compiler/mlir/lite/stablehlo:tfl_legalize_chlo",
+        "//tensorflow/compiler/mlir/lite/stablehlo:tfl_legalize_hlo",
+        "//tensorflow/compiler/mlir/quantization/common/ir:QuantOps",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib:quantization_config",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:convert_tensor",
+        "//tensorflow/compiler/mlir/tensorflow:dynamic_shape_utils",
+        "//tensorflow/compiler/mlir/tensorflow:error_util",
+        "//tensorflow/compiler/mlir/tensorflow:mangling_util",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_attributes",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_ops",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "//tensorflow/compiler/mlir/tensorflow:verification_utils",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:lower_tf_lib",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:tensorflow_passes",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:unroll_batch_matmul_pass",
+        "//tensorflow/compiler/mlir/tf2xla/transforms:xla_legalize_tf",
+        "//tensorflow/compiler/mlir/tf2xla/transforms:xla_legalize_tf_with_tf2xla",
+        "//tensorflow/core:framework",
+        "//tensorflow/core:lib",
+        "//tensorflow/core:protos_all_cc",
+        "//tensorflow/core/kernels:tensor_list",
+        "@com_google_absl//absl/algorithm:container",
+        "@com_google_absl//absl/container:flat_hash_set",
+        "@com_google_absl//absl/container:inlined_vector",
+        "@com_google_absl//absl/memory",
+        "@com_google_absl//absl/numeric:bits",
+        "@com_google_absl//absl/status",
+        "@com_google_absl//absl/status:statusor",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:AffineAnalysis",
+        "@llvm-project//mlir:Analysis",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:LoopLikeInterface",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:QuantOps",
+        "@llvm-project//mlir:SideEffectInterfaces",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+        "@llvm-project//mlir:Transforms",
+        "@local_xla//xla/mlir_hlo",
+        "@stablehlo//:stablehlo_ops",
+    ],
+)
+
+cc_library(
+    name = "bias_contract",
+    srcs = [
+        "BiasContract.cc",
+    ],
+    hdrs = [
+        "BiasContract.h",
+    ],
+    deps = [
+        ":attribute_utils",
+        ":constant_utils",
+        ":convert_type",
+        ":cost_estimators",
+        ":fake_quant_utils",
+        ":lstm_utils",
+        ":nms_utils",
+        ":perception_ops_utils",
+        ":size_utils",
+        ":stateful_ops_utils",
+        ":tensorflow_lite",
+        ":tensorflow_lite_legalize_tf_analyze_variables",
+        ":tensorflow_lite_legalize_tf_inc_gen",
+        ":tensorflow_lite_legalize_tf_legalize_tensorlist",
+        ":tensorflow_lite_legalize_variables_inc_gen",
+        ":tensorflow_lite_lower_static_tensor_list_inc_gen",
+        ":tensorflow_lite_passes_inc_gen",
+        ":tensorflow_lite_prepare_tf_inc_gen",
+        ":tensorflow_lite_tf_unfreeze_global_tensors",
+        ":tftext_utils",
+        ":validators",
+        ":variables_utils",
+        "//tensorflow/compiler/mlir:op_or_arg_name_mapper",
+        "//tensorflow/compiler/mlir/lite/quantization/ir:QuantOps",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs",
+        "//tensorflow/compiler/mlir/lite/stablehlo:legalize_tf",
+        "//tensorflow/compiler/mlir/lite/stablehlo:optimize_layout",
+        "//tensorflow/compiler/mlir/lite/stablehlo:prepare_hlo",
+        "//tensorflow/compiler/mlir/lite/stablehlo:tf_legalize_hlo",
+        "//tensorflow/compiler/mlir/lite/stablehlo:tfl_legalize_chlo",
+        "//tensorflow/compiler/mlir/lite/stablehlo:tfl_legalize_hlo",
+        "//tensorflow/compiler/mlir/quantization/common/ir:QuantOps",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib:quantization_config",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:convert_tensor",
+        "//tensorflow/compiler/mlir/tensorflow:dynamic_shape_utils",
+        "//tensorflow/compiler/mlir/tensorflow:error_util",
+        "//tensorflow/compiler/mlir/tensorflow:mangling_util",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_attributes",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_ops",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "//tensorflow/compiler/mlir/tensorflow:verification_utils",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:lower_tf_lib",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:tensorflow_passes",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:unroll_batch_matmul_pass",
+        "//tensorflow/compiler/mlir/tf2xla/transforms:xla_legalize_tf",
+        "//tensorflow/compiler/mlir/tf2xla/transforms:xla_legalize_tf_with_tf2xla",
+        "//tensorflow/core:framework",
+        "//tensorflow/core:lib",
+        "//tensorflow/core:protos_all_cc",
+        "//tensorflow/core/kernels:tensor_list",
+        "@com_google_absl//absl/algorithm:container",
+        "@com_google_absl//absl/container:flat_hash_set",
+        "@com_google_absl//absl/container:inlined_vector",
+        "@com_google_absl//absl/memory",
+        "@com_google_absl//absl/numeric:bits",
+        "@com_google_absl//absl/status",
+        "@com_google_absl//absl/status:statusor",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:AffineAnalysis",
+        "@llvm-project//mlir:Analysis",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:LoopLikeInterface",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:QuantOps",
+        "@llvm-project//mlir:SideEffectInterfaces",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+        "@llvm-project//mlir:Transforms",
+        "@local_xla//xla/mlir_hlo",
+        "@stablehlo//:stablehlo_ops",
+    ],
+)
+
+cc_library(
+    name = "dequant_contract",
+    srcs = [
+        "DequantContract.cc",
+    ],
+    hdrs = [
+        "DequantContract.h",
+    ],
+    deps = [
+        ":attribute_utils",
+        ":constant_utils",
+        ":convert_type",
+        ":cost_estimators",
+        ":fake_quant_utils",
+        ":lstm_utils",
+        ":nms_utils",
+        ":perception_ops_utils",
+        ":size_utils",
+        ":stateful_ops_utils",
+        ":tensorflow_lite",
+        ":tensorflow_lite_legalize_tf_analyze_variables",
+        ":tensorflow_lite_legalize_tf_inc_gen",
+        ":tensorflow_lite_legalize_tf_legalize_tensorlist",
+        ":tensorflow_lite_legalize_variables_inc_gen",
+        ":tensorflow_lite_lower_static_tensor_list_inc_gen",
+        ":tensorflow_lite_passes_inc_gen",
+        ":tensorflow_lite_prepare_tf_inc_gen",
+        ":tensorflow_lite_tf_unfreeze_global_tensors",
+        ":tftext_utils",
+        ":validators",
+        ":variables_utils",
+        "//tensorflow/compiler/mlir:op_or_arg_name_mapper",
+        "//tensorflow/compiler/mlir/lite/quantization/ir:QuantOps",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs",
+        "//tensorflow/compiler/mlir/lite/stablehlo:legalize_tf",
+        "//tensorflow/compiler/mlir/lite/stablehlo:optimize_layout",
+        "//tensorflow/compiler/mlir/lite/stablehlo:prepare_hlo",
+        "//tensorflow/compiler/mlir/lite/stablehlo:tf_legalize_hlo",
+        "//tensorflow/compiler/mlir/lite/stablehlo:tfl_legalize_chlo",
+        "//tensorflow/compiler/mlir/lite/stablehlo:tfl_legalize_hlo",
+        "//tensorflow/compiler/mlir/quantization/common/ir:QuantOps",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib:quantization_config",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:convert_tensor",
+        "//tensorflow/compiler/mlir/tensorflow:dynamic_shape_utils",
+        "//tensorflow/compiler/mlir/tensorflow:error_util",
+        "//tensorflow/compiler/mlir/tensorflow:mangling_util",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_attributes",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_ops",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "//tensorflow/compiler/mlir/tensorflow:verification_utils",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:lower_tf_lib",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:tensorflow_passes",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:unroll_batch_matmul_pass",
+        "//tensorflow/compiler/mlir/tf2xla/transforms:xla_legalize_tf",
+        "//tensorflow/compiler/mlir/tf2xla/transforms:xla_legalize_tf_with_tf2xla",
+        "//tensorflow/core:framework",
+        "//tensorflow/core:lib",
+        "//tensorflow/core:protos_all_cc",
+        "//tensorflow/core/kernels:tensor_list",
+        "@com_google_absl//absl/algorithm:container",
+        "@com_google_absl//absl/container:flat_hash_set",
+        "@com_google_absl//absl/container:inlined_vector",
+        "@com_google_absl//absl/memory",
+        "@com_google_absl//absl/numeric:bits",
+        "@com_google_absl//absl/status",
+        "@com_google_absl//absl/status:statusor",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:AffineAnalysis",
+        "@llvm-project//mlir:Analysis",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:LoopLikeInterface",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:QuantOps",
+        "@llvm-project//mlir:SideEffectInterfaces",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+        "@llvm-project//mlir:Transforms",
+        "@local_xla//xla/mlir_hlo",
+        "@stablehlo//:stablehlo_ops",
+    ],
+)
+
+cc_library(
+    name = "reshape_to_4d",
+    srcs = [
+        "ReshapeTo4D.cc",
+    ],
+    hdrs = [
+        "ReshapeTo4D.h",
+    ],
+    deps = [
+        ":attribute_utils",
+        ":constant_utils",
+        ":convert_type",
+        ":cost_estimators",
+        ":fake_quant_utils",
+        ":lstm_utils",
+        ":nms_utils",
+        ":perception_ops_utils",
+        ":size_utils",
+        ":stateful_ops_utils",
+        ":tensorflow_lite",
+        ":tensorflow_lite_legalize_tf_analyze_variables",
+        ":tensorflow_lite_legalize_tf_inc_gen",
+        ":tensorflow_lite_legalize_tf_legalize_tensorlist",
+        ":tensorflow_lite_legalize_variables_inc_gen",
+        ":tensorflow_lite_lower_static_tensor_list_inc_gen",
+        ":tensorflow_lite_passes_inc_gen",
+        ":tensorflow_lite_prepare_tf_inc_gen",
+        ":tensorflow_lite_tf_unfreeze_global_tensors",
+        ":tftext_utils",
+        ":validators",
+        ":variables_utils",
+        "//tensorflow/compiler/mlir:op_or_arg_name_mapper",
+        "//tensorflow/compiler/mlir/lite/quantization/ir:QuantOps",
+        "//tensorflow/compiler/mlir/lite/schema:schema_fbs",
+        "//tensorflow/compiler/mlir/lite/stablehlo:legalize_tf",
+        "//tensorflow/compiler/mlir/lite/stablehlo:optimize_layout",
+        "//tensorflow/compiler/mlir/lite/stablehlo:prepare_hlo",
+        "//tensorflow/compiler/mlir/lite/stablehlo:tf_legalize_hlo",
+        "//tensorflow/compiler/mlir/lite/stablehlo:tfl_legalize_chlo",
+        "//tensorflow/compiler/mlir/lite/stablehlo:tfl_legalize_hlo",
+        "//tensorflow/compiler/mlir/quantization/common/ir:QuantOps",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib",
+        "//tensorflow/compiler/mlir/quantization/common/quantization_lib:quantization_config",
+        "//tensorflow/compiler/mlir/tensorflow",
+        "//tensorflow/compiler/mlir/tensorflow:convert_tensor",
+        "//tensorflow/compiler/mlir/tensorflow:dynamic_shape_utils",
+        "//tensorflow/compiler/mlir/tensorflow:error_util",
+        "//tensorflow/compiler/mlir/tensorflow:mangling_util",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_attributes",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_ops",
+        "//tensorflow/compiler/mlir/tensorflow:tensorflow_types",
+        "//tensorflow/compiler/mlir/tensorflow:verification_utils",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:lower_tf_lib",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:tensorflow_passes",
+        "//tensorflow/compiler/mlir/tensorflow/transforms:unroll_batch_matmul_pass",
+        "//tensorflow/compiler/mlir/tf2xla/transforms:xla_legalize_tf",
+        "//tensorflow/compiler/mlir/tf2xla/transforms:xla_legalize_tf_with_tf2xla",
+        "//tensorflow/core:framework",
+        "//tensorflow/core:lib",
+        "//tensorflow/core:protos_all_cc",
+        "//tensorflow/core/kernels:tensor_list",
+        "@com_google_absl//absl/algorithm:container",
+        "@com_google_absl//absl/container:flat_hash_set",
+        "@com_google_absl//absl/container:inlined_vector",
+        "@com_google_absl//absl/memory",
+        "@com_google_absl//absl/numeric:bits",
+        "@com_google_absl//absl/status",
+        "@com_google_absl//absl/status:statusor",
+        "@llvm-project//llvm:Support",
+        "@llvm-project//mlir:AffineAnalysis",
+        "@llvm-project//mlir:Analysis",
+        "@llvm-project//mlir:ArithDialect",
+        "@llvm-project//mlir:FuncDialect",
+        "@llvm-project//mlir:IR",
+        "@llvm-project//mlir:LoopLikeInterface",
+        "@llvm-project//mlir:Pass",
+        "@llvm-project//mlir:QuantOps",
+        "@llvm-project//mlir:SideEffectInterfaces",
+        "@llvm-project//mlir:Support",
+        "@llvm-project//mlir:TransformUtils",
+        "@llvm-project//mlir:Transforms",
+        "@local_xla//xla/mlir_hlo",
+        "@stablehlo//:stablehlo_ops",
+    ],
+)
diff --git a/tensorflow/compiler/mlir/lite/BiasContract.cc b/tensorflow/compiler/mlir/lite/BiasContract.cc
new file mode 100644
index 00000000000..737cf9d0a91
--- /dev/null
+++ b/tensorflow/compiler/mlir/lite/BiasContract.cc
@@ -0,0 +1,126 @@
+#include "BiasContract.h"
+
+#include "llvm/ADT/ArrayRef.h"
+#include "llvm/Support/Casting.h"
+#include "mlir/Dialect/Arith/IR/Arith.h"  // from @llvm-project
+#include "mlir/Dialect/Quant/IR/QuantTypes.h"  // from @llvm-project
+#include "mlir/IR/BuiltinAttributes.h"  // from @llvm-project
+#include "mlir/IR/BuiltinTypeInterfaces.h"  // from @llvm-project
+#include "mlir/IR/BuiltinTypes.h"  // from @llvm-project
+#include "mlir/IR/Location.h"  // from @llvm-project
+#include "mlir/IR/MLIRContext.h"  // from @llvm-project
+#include "mlir/IR/PatternMatch.h"  // from @llvm-project
+#include "mlir/IR/TypeUtilities.h"  // from @llvm-project
+#include "mlir/Pass/Pass.h"  // from @llvm-project
+#include "mlir/Support/LLVM.h"  // from @llvm-project
+#include "mlir/Support/LogicalResult.h"  // from @llvm-project
+#include "mlir/Transforms/GreedyPatternRewriteDriver.h"  // from @llvm-project
+#include "tensorflow/compiler/mlir/lite/ir/tfl_ops.h"
+#include "tensorflow/compiler/mlir/quantization/common/quantization_lib/quantization_config.h"
+#include "tensorflow/compiler/mlir/quantization/common/quantization_lib/quantization_utils.h"
+#include "tensorflow/compiler/mlir/lite/transforms/passes.h"
+#include "tensorflow/compiler/mlir/tensorflow/utils/dynamic_shape_utils.h"
+
+#include <iostream>
+#include <typeinfo>
+
+namespace mlir {
+namespace TFL {
+
+void BiasContract::runOnOperation() {
+  RewritePatternSet patterns(&getContext());
+  auto func = getOperation(); // 함수들을 가져옴
+  auto* ctx = func.getContext();  // 등록된 dialect들을 가져옴 (tf, tfl, quant, ...)
+
+  PatternRewriter rewriter(ctx);  // op를 추가, 변경하기 위한 rewriter
+
+  func.walk([&](FullyConnectedOp fc_op) {
+    // fc의 bias tensor를 가져옴
+    Value fcBiasValue = fc_op.getBias();
+    if (!fcBiasValue) return;
+
+    // <1x1x1xC> ranked tensor인지 검사
+    RankedTensorType fcBiasType = dyn_cast<RankedTensorType>(fcBiasValue.getType());
+    if (!fcBiasType) return;
+    int rnk = fcBiasType.getRank();
+    if (rnk <= 1) return;
+    auto sh = fcBiasType.getShape();
+    for (int i = 0; i < rnk - 1; i++) {
+      if (!sh[i] > 1) {
+        std::cerr << "Bias tensor has non-1 dimensions before the last dimension.\n";
+        return;
+      }
+    }
+
+    int64_t C = sh[rnk - 1];
+    Type elemTy = fcBiasType.getElementType();
+    auto newTensorTy = RankedTensorType::get({C}, elemTy);
+
+    if (Operation *def = fcBiasValue.getDefiningOp()) {
+      if (def->getName().getStringRef() == "tfl.pseudo_qconst") {
+        auto valueAttr = def->getAttrOfType<DenseElementsAttr>("value");
+        auto qtypeAttr = def->getAttrOfType<TypeAttr>("qtype");
+        if (!valueAttr || !qtypeAttr) return;
+        auto oldQTensorTy = dyn_cast<RankedTensorType>(qtypeAttr.getValue());
+        if (!oldQTensorTy) return;
+        int rnkQ = oldQTensorTy.getRank();
+        if (rnkQ <= 1) return;
+        auto shQ = oldQTensorTy.getShape();
+        for (int i = 0; i < rnkQ - 1; i++) {
+          if (!shQ[i] > 1) {
+            std::cerr << "Bias tensor has non-1 dimensions before the last dimension.\n";
+            return;
+          }
+        }
+        int64_t Cq = shQ[rnkQ - 1];
+
+        // Build new *qtype/result* using the same quantized element type
+        Type quantElemTy = oldQTensorTy.getElementType();              // e.g., !quant.uniform<i32:f32, ...>
+        auto newQTensorTy = RankedTensorType::get({Cq}, quantElemTy);  // tensor<C x !quant...>
+
+        // reshape raw i32 payload: <1x1x1xC xi32> -> <C xi32>
+        auto i32 = IntegerType::get(def->getContext(), 32);
+        auto newRawTy = RankedTensorType::get({Cq}, i32);
+        auto newValueAttr = valueAttr.reshape(newRawTy);
+
+        // build new 1-D pseudo_qconst
+        OperationState pqc_st(fc_op.getLoc(), "tfl.pseudo_qconst");
+        pqc_st.addTypes(newQTensorTy);
+        pqc_st.addAttribute("value", newValueAttr);
+        pqc_st.addAttribute("qtype", TypeAttr::get(newQTensorTy));
+
+        rewriter.setInsertionPoint(fc_op);
+        Operation *newPqc = rewriter.create(pqc_st);
+        Value newBias = newPqc->getResult(0);
+
+        auto newFc = rewriter.replaceOpWithNewOp<FullyConnectedOp>(
+          fc_op,
+          fc_op.getResult(0).getType(),
+          fc_op.getInput(), fc_op.getFilter(), newBias,
+          fc_op.getFusedActivationFunctionAttr(),
+          fc_op.getWeightsFormatAttr(),
+          fc_op.getKeepNumDimsAttr(),
+          fc_op.getAsymmetricQuantizeInputsAttr());
+      } else {
+        // Generic producer: if you know it's safe to reinterpret its output,
+        // just change its result type to 1D.
+        rewriter.setInsertionPoint(def);
+        def->getResult(0).setType(newTensorTy);
+      }
+
+      // cleanup old bias chain if dead
+      if (def->getResult(0).use_empty()) {
+        rewriter.eraseOp(def);
+      }
+      return;
+    }
+
+  });
+}
+
+std::unique_ptr<OperationPass<func::FuncOp>> CreateBiasContract() {
+  return std::make_unique<BiasContract>();
+}
+
+} // namespace TFL
+} // namespace mlir
\ No newline at end of file
diff --git a/tensorflow/compiler/mlir/lite/BiasContract.h b/tensorflow/compiler/mlir/lite/BiasContract.h
new file mode 100644
index 00000000000..b867c350b07
--- /dev/null
+++ b/tensorflow/compiler/mlir/lite/BiasContract.h
@@ -0,0 +1,35 @@
+#include <cstddef>
+#include <string>
+#include <type_traits>
+#include <utility>
+#include <memory>
+
+#include "llvm/ADT/StringRef.h"
+#include "mlir/Pass/Pass.h"  // from @llvm-project
+#include "mlir/Dialect/Func/IR/FuncOps.h"  // from @llvm-project
+#include "mlir/Support/LLVM.h"  // from @llvm-project
+
+namespace mlir {
+namespace TFL {
+
+std::unique_ptr<OperationPass<func::FuncOp>> CreateBiasContract();
+
+#define GEN_PASS_DECL_DEQUANTSPLIT
+#include "tensorflow/compiler/mlir/lite/transforms/passes.h.inc"
+
+class BiasContract
+    : public PassWrapper<BiasContract, OperationPass<func::FuncOp>> {
+public:
+    MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(BiasContract)
+
+    void runOnOperation() override;
+
+    StringRef getArgument() const final { return "bias-contract"; }
+
+    StringRef getDescription() const final {
+        return "Contract FC biases <1x1x1xX> -> <X>";
+    }
+};
+ 
+}
+}
\ No newline at end of file
diff --git a/tensorflow/compiler/mlir/lite/DequantContract.cc b/tensorflow/compiler/mlir/lite/DequantContract.cc
new file mode 100644
index 00000000000..6a78d9773ed
--- /dev/null
+++ b/tensorflow/compiler/mlir/lite/DequantContract.cc
@@ -0,0 +1,94 @@
+#include "DequantContract.h"
+
+#include "llvm/ADT/ArrayRef.h"
+#include "llvm/Support/Casting.h"
+#include "mlir/Dialect/Arith/IR/Arith.h"  // from @llvm-project
+#include "mlir/Dialect/Quant/IR/QuantTypes.h"  // from @llvm-project
+#include "mlir/IR/BuiltinAttributes.h"  // from @llvm-project
+#include "mlir/IR/BuiltinTypeInterfaces.h"  // from @llvm-project
+#include "mlir/IR/BuiltinTypes.h"  // from @llvm-project
+#include "mlir/IR/Location.h"  // from @llvm-project
+#include "mlir/IR/MLIRContext.h"  // from @llvm-project
+#include "mlir/IR/PatternMatch.h"  // from @llvm-project
+#include "mlir/IR/TypeUtilities.h"  // from @llvm-project
+#include "mlir/Pass/Pass.h"  // from @llvm-project
+#include "mlir/Support/LLVM.h"  // from @llvm-project
+#include "mlir/Support/LogicalResult.h"  // from @llvm-project
+#include "mlir/Transforms/GreedyPatternRewriteDriver.h"  // from @llvm-project
+#include "tensorflow/compiler/mlir/lite/ir/tfl_ops.h"
+#include "tensorflow/compiler/mlir/quantization/common/quantization_lib/quantization_config.h"
+#include "tensorflow/compiler/mlir/quantization/common/quantization_lib/quantization_utils.h"
+#include "tensorflow/compiler/mlir/lite/transforms/passes.h"
+#include "tensorflow/compiler/mlir/tensorflow/utils/dynamic_shape_utils.h"
+
+#include <iostream>
+#include <typeinfo>
+
+namespace mlir {
+namespace TFL {
+
+void DequantContract::runOnOperation() {
+  RewritePatternSet patterns(&getContext());
+  auto func = getOperation(); // 함수들을 가져옴
+  auto* ctx = func.getContext();  // 등록된 dialect들을 가져옴 (tf, tfl, quant, ...)
+
+  PatternRewriter rewriter(ctx);  // op를 추가, 변경하기 위한 rewriter
+
+  func.walk([&](DequantizeOp deq) {
+    // ranked tensor인지 검사
+    RankedTensorType inTy = dyn_cast<RankedTensorType>(deq.getInput().getType());
+    // 5차원이 아니면 return
+    if (!inTy || inTy.getRank() != 5) return;
+    // per-channel quantize면 return
+    if (dyn_cast<quant::UniformQuantizedPerAxisType>(inTy.getElementType())) return;
+
+    // dimension을 가져옴
+    auto d = llvm::to_vector(inTy.getShape()); 
+    // dynamic tensor면 return
+    for (int i = 0; i < 5; i++) {
+      if (ShapedType::isDynamic(d[i])) return;
+    }
+    // 0차원과 1차원을 합침
+    int64_t fused01 = d[0] * d[1];
+
+    // 타입
+    auto i32 = rewriter.getI32Type();
+    auto f32 = rewriter.getF32Type();
+    auto elemQ = inTy.getElementType();
+    llvm::SmallVector<int64_t, 4> s4 { fused01, d[2], d[3], d[4] };
+    auto q4Ty = RankedTensorType::get(s4, elemQ);
+    auto f4Ty = RankedTensorType::get(s4, f32);
+    auto f5Ty = RankedTensorType::get(d, f32);
+
+    // Shape consts
+    auto vec4Ty = RankedTensorType::get({4}, i32);
+    auto vec5Ty = RankedTensorType::get({5}, i32);
+    llvm::SmallVector<int32_t,4> c4{
+      static_cast<int32_t>(s4[0]), static_cast<int32_t>(s4[1]),
+      static_cast<int32_t>(s4[2]), static_cast<int32_t>(s4[3])};
+    llvm::SmallVector<int32_t,5> c5{
+      static_cast<int32_t>(d[0]), static_cast<int32_t>(d[1]),
+      static_cast<int32_t>(d[2]), static_cast<int32_t>(d[3]),
+      static_cast<int32_t>(d[4])};
+
+    auto c4Attr = DenseIntElementsAttr::get(vec4Ty, c4);
+    auto c5Attr = DenseIntElementsAttr::get(vec5Ty, c5);
+
+    rewriter.setInsertionPoint(deq); 
+    auto shape4 = rewriter.create<ConstOp>(deq.getLoc(), vec4Ty, c4Attr);
+    auto shape5 = rewriter.create<ConstOp>(deq.getLoc(), vec5Ty, c5Attr);
+    auto q4 = rewriter.create<ReshapeOp>(deq.getLoc(), q4Ty, deq.getInput(), shape4);
+    auto f4 = rewriter.create<DequantizeOp>(deq.getLoc(), f4Ty, q4.getOutput());
+    auto f5 = rewriter.create<ReshapeOp>(deq.getLoc(), f5Ty, f4.getOutput(), shape5);
+
+    rewriter.replaceOp(deq, f5.getOutput());
+    return;
+  });
+}
+
+std::unique_ptr<OperationPass<func::FuncOp>> CreateDequantContract() {
+  return std::make_unique<DequantContract>();
+}
+
+} // namespace TFL
+} // namespace mlir
\ No newline at end of file
diff --git a/tensorflow/compiler/mlir/lite/DequantContract.h b/tensorflow/compiler/mlir/lite/DequantContract.h
new file mode 100644
index 00000000000..c532befc6ce
--- /dev/null
+++ b/tensorflow/compiler/mlir/lite/DequantContract.h
@@ -0,0 +1,35 @@
+#include <cstddef>
+#include <string>
+#include <type_traits>
+#include <utility>
+#include <memory>
+
+#include "llvm/ADT/StringRef.h"
+#include "mlir/Pass/Pass.h"  // from @llvm-project
+#include "mlir/Dialect/Func/IR/FuncOps.h"  // from @llvm-project
+#include "mlir/Support/LLVM.h"  // from @llvm-project
+
+namespace mlir {
+namespace TFL {
+
+std::unique_ptr<OperationPass<func::FuncOp>> CreateDequantContract();
+
+#define GEN_PASS_DECL_DEQUANTSPLIT
+#include "tensorflow/compiler/mlir/lite/transforms/passes.h.inc"
+
+class DequantContract
+    : public PassWrapper<DequantContract, OperationPass<func::FuncOp>> {
+public:
+    MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(DequantContract)
+
+    void runOnOperation() override;
+
+    StringRef getArgument() const final { return "dequant-contract"; }
+
+    StringRef getDescription() const final {
+        return "Contract 5D dequantize ops <AxBxCxDxE> -> <(A*B)XCXDXE>";
+    }
+};
+ 
+}
+}
\ No newline at end of file
diff --git a/tensorflow/compiler/mlir/lite/DequantSplit.cc b/tensorflow/compiler/mlir/lite/DequantSplit.cc
new file mode 100644
index 00000000000..65360984a9e
--- /dev/null
+++ b/tensorflow/compiler/mlir/lite/DequantSplit.cc
@@ -0,0 +1,94 @@
+#include "DequantSplit.h"
+
+#include "llvm/ADT/ArrayRef.h"
+#include "llvm/Support/Casting.h"
+#include "mlir/Dialect/Arith/IR/Arith.h"  // from @llvm-project
+#include "mlir/Dialect/Quant/IR/QuantTypes.h"  // from @llvm-project
+#include "mlir/IR/BuiltinAttributes.h"  // from @llvm-project
+#include "mlir/IR/BuiltinTypeInterfaces.h"  // from @llvm-project
+#include "mlir/IR/BuiltinTypes.h"  // from @llvm-project
+#include "mlir/IR/Location.h"  // from @llvm-project
+#include "mlir/IR/MLIRContext.h"  // from @llvm-project
+#include "mlir/IR/PatternMatch.h"  // from @llvm-project
+#include "mlir/IR/TypeUtilities.h"  // from @llvm-project
+#include "mlir/Pass/Pass.h"  // from @llvm-project
+#include "mlir/Support/LLVM.h"  // from @llvm-project
+#include "mlir/Support/LogicalResult.h"  // from @llvm-project
+#include "mlir/Transforms/GreedyPatternRewriteDriver.h"  // from @llvm-project
+#include "tensorflow/compiler/mlir/lite/ir/tfl_ops.h"
+#include "tensorflow/compiler/mlir/quantization/common/quantization_lib/quantization_config.h"
+#include "tensorflow/compiler/mlir/quantization/common/quantization_lib/quantization_utils.h"
+#include "tensorflow/compiler/mlir/lite/transforms/passes.h"
+#include "tensorflow/compiler/mlir/tensorflow/utils/dynamic_shape_utils.h"
+
+#include <iostream>
+#include <typeinfo>
+
+namespace mlir {
+namespace TFL {
+
+void DequantSplit::runOnOperation() {
+  RewritePatternSet patterns(&getContext());
+  auto func = getOperation(); // 함수들을 가져옴
+  auto* ctx = func.getContext();  // 등록된 dialect들을 가져옴 (tf, tfl, quant, ...)
+
+  PatternRewriter rewriter(ctx);  // op를 추가, 변경하기 위한 rewriter
+
+  func.walk([&](DequantizeOp deq_op) {
+    // dequantize의 input tensor를 가져옴
+    auto deq_input_value = deq_op.getInput();
+
+    // ranked tensor인지 검사
+    RankedTensorType deq_input_type = dyn_cast<RankedTensorType>(deq_input_value.getType());
+    if (!deq_input_type) return;
+
+    // element가 signed quantized type인지 검사
+    auto deq_elem_type = dyn_cast<quant::UniformQuantizedType>(deq_input_type.getElementType());
+    if (!deq_elem_type) return;
+    if (!deq_elem_type.isSigned()) return;
+
+    // scale, zero point, shape 가져옴
+    long double scale = deq_elem_type.getScale();
+    int64_t zero_point = deq_elem_type.getZeroPoint();
+    auto deq_input_shape = deq_input_type.getShape();
+    // zero point에 128 더함
+    int64_t shifted_zero_point = zero_point + 128;
+
+    // 부호 없는 8비트로 storage type 생성
+    auto u8_type = rewriter.getIntegerType(8, /*isSigned=*/false);
+
+    // quantize type 생성
+    auto new_q_type = quant::UniformQuantizedType::get(
+      /*flags=u8*/0,
+      /*storageType=*/u8_type,
+      /*expressedType=*/deq_elem_type.getExpressedType(),
+      /*scale=*/scale,
+      /*zeroPoint=*/shifted_zero_point,
+      /*storageTypeMin=*/0,
+      /*storageTypeMax=*/255);
+        
+    // quantize tensor 생성
+    auto new_q_tensor = RankedTensorType::get(deq_input_shape, new_q_type);
+
+    // dequantize 앞으로 rewriter를 옮김
+    rewriter.setInsertionPoint(deq_op);
+
+    // quantize op 생성
+    auto new_q_op = rewriter.create<QuantizeOp>(
+      deq_op.getLoc(),
+      new_q_tensor,
+      deq_input_value,
+      rewriter.getNamedAttr("qtype", TypeAttr::get(new_q_tensor)));
+
+    // dequantize의 input을 새로 생성된 quantize op로 설정
+    deq_op->setOperand(0, new_q_op.getResult());
+
+  });
+}
+
+std::unique_ptr<OperationPass<func::FuncOp>> CreateDequantSplit() {
+  return std::make_unique<DequantSplit>();
+}
+
+} // namespace TFL
+} // namespace mlir
\ No newline at end of file
diff --git a/tensorflow/compiler/mlir/lite/DequantSplit.h b/tensorflow/compiler/mlir/lite/DequantSplit.h
new file mode 100644
index 00000000000..b0db0a58db0
--- /dev/null
+++ b/tensorflow/compiler/mlir/lite/DequantSplit.h
@@ -0,0 +1,35 @@
+#include <cstddef>
+#include <string>
+#include <type_traits>
+#include <utility>
+#include <memory>
+
+#include "llvm/ADT/StringRef.h"
+#include "mlir/Pass/Pass.h"  // from @llvm-project
+#include "mlir/Dialect/Func/IR/FuncOps.h"  // from @llvm-project
+#include "mlir/Support/LLVM.h"  // from @llvm-project
+
+namespace mlir {
+namespace TFL {
+
+std::unique_ptr<OperationPass<func::FuncOp>> CreateDequantSplit();
+
+#define GEN_PASS_DECL_DEQUANTSPLIT
+#include "tensorflow/compiler/mlir/lite/transforms/passes.h.inc"
+
+class DequantSplit
+    : public PassWrapper<DequantSplit, OperationPass<func::FuncOp>> {
+public:
+    MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(DequantSplit)
+
+    void runOnOperation() override;
+
+    StringRef getArgument() const final { return "dequant-split"; }
+
+    StringRef getDescription() const final {
+        return "Split dequantization ops";
+    }
+};
+ 
+}
+}
\ No newline at end of file
diff --git a/tensorflow/compiler/mlir/lite/ReshapeTo4D.cc b/tensorflow/compiler/mlir/lite/ReshapeTo4D.cc
new file mode 100644
index 00000000000..ba96d23f1a5
--- /dev/null
+++ b/tensorflow/compiler/mlir/lite/ReshapeTo4D.cc
@@ -0,0 +1,118 @@
+#include "ReshapeTo4D.h"
+
+#include "llvm/ADT/ArrayRef.h"
+#include "llvm/Support/Casting.h"
+#include "mlir/Dialect/Arith/IR/Arith.h"  // from @llvm-project
+#include "mlir/Dialect/Quant/IR/QuantTypes.h"  // from @llvm-project
+#include "mlir/IR/BuiltinAttributes.h"  // from @llvm-project
+#include "mlir/IR/BuiltinTypeInterfaces.h"  // from @llvm-project
+#include "mlir/IR/BuiltinTypes.h"  // from @llvm-project
+#include "mlir/IR/Location.h"  // from @llvm-project
+#include "mlir/IR/MLIRContext.h"  // from @llvm-project
+#include "mlir/IR/PatternMatch.h"  // from @llvm-project
+#include "mlir/IR/TypeUtilities.h"  // from @llvm-project
+#include "mlir/Pass/Pass.h"  // from @llvm-project
+#include "mlir/Support/LLVM.h"  // from @llvm-project
+#include "mlir/Support/LogicalResult.h"  // from @llvm-project
+#include "mlir/Transforms/GreedyPatternRewriteDriver.h"  // from @llvm-project
+#include "tensorflow/compiler/mlir/lite/ir/tfl_ops.h"
+#include "tensorflow/compiler/mlir/quantization/common/quantization_lib/quantization_config.h"
+#include "tensorflow/compiler/mlir/quantization/common/quantization_lib/quantization_utils.h"
+#include "tensorflow/compiler/mlir/lite/transforms/passes.h"
+#include "tensorflow/compiler/mlir/tensorflow/utils/dynamic_shape_utils.h"
+
+#include <iostream>
+#include <typeinfo>
+
+namespace mlir {
+namespace TFL {
+
+void ReshapeTo4D::runOnOperation() {
+  RewritePatternSet patterns(&getContext());
+  auto func = getOperation(); // 함수들을 가져옴
+  auto* ctx = func.getContext();  // 등록된 dialect들을 가져옴 (tf, tfl, quant, ...)
+
+  PatternRewriter rewriter(ctx);  // op를 추가, 변경하기 위한 rewriter
+
+  func.walk([&](FullyConnectedOp fc) {
+    // ranked tensor인지 검사
+    Value input = fc.getInput();
+    RankedTensorType inTy = dyn_cast<RankedTensorType>(input.getType());
+    if (!inTy) return;
+    // 4차원 이하면 return
+    auto rank = inTy.getRank();
+    if (rank <= 4) return;
+
+    // dimension을 가져옴
+    auto d = llvm::to_vector(inTy.getShape()); 
+    // dynamic tensor면 return
+    for (int i = 0; i < rank; i++) {
+      if (ShapedType::isDynamic(d[i])) return;
+    }
+
+    // n-2, n-1, n차원을 제외한 차원들을 합침
+    int64_t fused = 1;
+    for (int i = 0; i < rank - 3; i++) {
+      fused *= d[i];
+    }
+
+    // 4차원
+    llvm::SmallVector<int64_t, 4> to4d { fused, d[rank - 3], d[rank - 2], d[rank - 1] };
+    auto i32Ty = rewriter.getI32Type();
+    auto vec4Ty = RankedTensorType::get({4}, i32Ty);
+    llvm::SmallVector<int32_t, 4> to4dI32 = {
+      static_cast<int32_t>(to4d[0]),
+      static_cast<int32_t>(to4d[1]),
+      static_cast<int32_t>(to4d[2]),
+      static_cast<int32_t>(to4d[3])
+    };
+    auto sh4Attr = DenseIntElementsAttr::get(vec4Ty, to4dI32);
+
+    rewriter.setInsertionPoint(fc);
+    Location loc = fc.getLoc();
+    auto sh4 = rewriter.create<ConstOp>(loc, vec4Ty, sh4Attr);
+    auto to4dTy = RankedTensorType::get(to4d, inTy.getElementType());
+    auto in4d = rewriter.create<ReshapeOp>(loc, to4dTy, input, sh4.getOutput());
+
+    // fc 입력 교체
+    fc.getInputMutable().assign(in4d.getOutput());
+
+    Value output = fc.getResult(0);
+    RankedTensorType outTy = dyn_cast<RankedTensorType>(output.getType());
+    if (!outTy) return;
+
+    // fc 출력 채널 수
+    int64_t units = outTy.getShape().back();
+    // n차원
+    llvm::SmallVector<int64_t> toNd;
+    for (int i = 0; i < rank - 3; i++) {
+      toNd.push_back(d[i]);
+    }
+    toNd.push_back(d[rank - 3]);
+    toNd.push_back(d[rank - 2]);
+    toNd.push_back(units);
+    
+    auto vecNTy = RankedTensorType::get({rank}, i32Ty);
+    llvm::SmallVector<int32_t> toNdI32;
+    for (int i = 0; i < rank; i++) {
+      toNdI32.push_back(static_cast<int32_t>(toNd[i]));
+    }
+    auto shNAttr = DenseIntElementsAttr::get(vecNTy, toNdI32);
+    
+    rewriter.setInsertionPointAfter(fc);
+    auto shN = rewriter.create<ConstOp>(loc, vecNTy, shNAttr);
+    auto toNdTy = RankedTensorType::get(toNd, outTy.getElementType());
+    auto outNd = rewriter.create<ReshapeOp>(loc, toNdTy, output, shN.getOutput());
+
+    // 새 결과로 교체 (outNd 자신은 예외)
+    rewriter.replaceAllUsesExcept(output, outNd.getResult(), outNd.getOperation());
+    return;
+  });
+}
+
+std::unique_ptr<OperationPass<func::FuncOp>> CreateReshapeTo4D() {
+  return std::make_unique<ReshapeTo4D>();
+}
+
+}  // namespace TFL
+}  // namespace mlir
\ No newline at end of file
diff --git a/tensorflow/compiler/mlir/lite/ReshapeTo4D.h b/tensorflow/compiler/mlir/lite/ReshapeTo4D.h
new file mode 100644
index 00000000000..12cb8e61747
--- /dev/null
+++ b/tensorflow/compiler/mlir/lite/ReshapeTo4D.h
@@ -0,0 +1,35 @@
+#include <cstddef>
+#include <string>
+#include <type_traits>
+#include <utility>
+#include <memory>
+
+#include "llvm/ADT/StringRef.h"
+#include "mlir/Pass/Pass.h"  // from @llvm-project
+#include "mlir/Dialect/Func/IR/FuncOps.h"  // from @llvm-project
+#include "mlir/Support/LLVM.h"  // from @llvm-project
+
+namespace mlir {
+namespace TFL {
+
+std::unique_ptr<OperationPass<func::FuncOp>> CreateReshapeTo4D();
+
+#define GEN_PASS_DECL_DEQUANTSPLIT
+#include "tensorflow/compiler/mlir/lite/transforms/passes.h.inc"
+
+class ReshapeTo4D
+    : public PassWrapper<ReshapeTo4D, OperationPass<func::FuncOp>> {
+public:
+    MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(ReshapeTo4D)
+
+    void runOnOperation() override;
+
+    StringRef getArgument() const final { return "reshape-to-4D"; }
+
+    StringRef getDescription() const final {
+        return "Reshape inputs of FC ops to 4D";
+    }
+};
+
+}
+}
\ No newline at end of file
diff --git a/tensorflow/compiler/mlir/lite/transforms/passes.h b/tensorflow/compiler/mlir/lite/transforms/passes.h
new file mode 100644
index 00000000000..fb09e12f8bc
--- /dev/null
+++ b/tensorflow/compiler/mlir/lite/transforms/passes.h
@@ -0,0 +1,368 @@
+/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+#ifndef TENSORFLOW_COMPILER_MLIR_LITE_TRANSFORMS_PASSES_H_
+#define TENSORFLOW_COMPILER_MLIR_LITE_TRANSFORMS_PASSES_H_
+
+#include <memory>
+#include <string>
+
+#include "absl/container/flat_hash_set.h"
+#include "mlir/Pass/Pass.h"  // from @llvm-project
+#include "mlir/Pass/PassRegistry.h"  // from @llvm-project  // IWYU pragma: keep
+#include "tensorflow/compiler/mlir/lite/transforms/canonicalize_boundary_value_pass.h"
+#include "tensorflow/compiler/mlir/lite/transforms/optimize_batch_matmul_pass.h"
+#include "tensorflow/compiler/mlir/lite/transforms/optimize_broadcast_like_pass.h"
+#include "tensorflow/compiler/mlir/lite/transforms/optimize_pass.h"
+#include "tensorflow/compiler/mlir/lite/transforms/pass_registry_utils.h"
+#include "tensorflow/compiler/mlir/lite/transforms/push_transpose_through_ewise_pass.h"
+#include "tensorflow/compiler/mlir/lite/transforms/tf_legalizations/analyze_variables_pass.h"
+#include "tensorflow/compiler/mlir/lite/transforms/tf_legalizations/legalize_tensorlist_pass.h"
+#include "tensorflow/compiler/mlir/lite/transforms/tf_legalizations/while_loop_outline_pass.h"
+#include "tensorflow/compiler/mlir/lite/transforms/tflite_passes/split_merged_operands_pass.h"
+#include "tensorflow/compiler/mlir/lite/transforms/tflite_passes/unfold_large_splat_constants_pass.h"
+#include "tensorflow/compiler/mlir/lite/transforms/unfreeze_global_constants.h"
+#include "tensorflow/compiler/mlir/quantization/common/quantization_lib/quantization_config.h"
+
+namespace mlir {
+namespace quant {
+class QuantDialect;
+}
+namespace quantfork {
+class QuantizationForkDialect;
+}
+namespace mhlo {
+class MhloDialect;
+}
+namespace TF {
+class TensorFlowDialect;
+}
+namespace TFL {
+class TFLDialect;
+typedef TFLDialect TensorFlowLiteDialect;
+}  // namespace TFL
+namespace func {
+class FuncOp;
+}
+class ModuleOp;
+template <typename T>
+class OperationPass;
+class Type;
+
+namespace TFL {
+
+////////////////////////////////////////////////////////////////////////////////
+// Forward declarations
+////////////////////////////////////////////////////////////////////////////////
+
+struct OptimizePassOptions;
+
+////////////////////////////////////////////////////////////////////////////////
+// Utilities for backward compatibility
+////////////////////////////////////////////////////////////////////////////////
+
+// Creates an instance of the TensorFlow Lite dialect LegalizeTF pass.
+// When the given run_tfl_runtime_verification value is true, it will check each
+// TFL builtin op towards the TFL runtime capability and the incompatible TF ops
+// will be left in the graph without getting legalized. If `preserve_assert_op`
+// is true, the TF::AssertOp will not be removed.
+std::unique_ptr<OperationPass<func::FuncOp>> CreateLegalizeTFPass(
+    bool run_tfl_runtime_verification, bool preserve_assert_op = false);
+std::unique_ptr<OperationPass<func::FuncOp>> CreateLegalizeTFPass();
+
+// Creates an instance of the TensorFlow Lite dialect Optimize pass.
+inline std::unique_ptr<mlir::Pass> CreateOptimizePass() {
+  return Create<OptimizePass>();
+}
+
+// Creates an instance of the Tensorflow Lite batch matmul Optimize pass.
+inline std::unique_ptr<mlir::Pass> CreateOptimizeBatchMatmulPass() {
+  return Create<OptimizeBatchMatmulPass>();
+}
+
+// Creates an instance of the TensorFlow Lite dialect PrepareTF pass.
+std::unique_ptr<OperationPass<func::FuncOp>> CreatePrepareTFPass(
+    bool unfold_batch_matmul, bool allow_bf16_and_f16_type_legalization,
+    bool use_fake_quant_num_bits = false);
+std::unique_ptr<OperationPass<func::FuncOp>> CreatePrepareTFPass();
+
+// Creates an instance of the TensorFlow Lite dialect LowerStaticTensorList
+// pass.
+std::unique_ptr<OperationPass<ModuleOp>> CreateLowerStaticTensorListPass(
+    bool allow_tensorlist_pass_through, bool default_to_single_batch,
+    bool enable_dynamic_update_slice);
+
+std::unique_ptr<OperationPass<ModuleOp>> CreateLowerStaticTensorListPass();
+
+// Creates an instance of the TensorFlow Lite dialect Quantize pass.
+// Use quant_specs.ops_blocklist and quant_specs.nodes_blocklist if possible
+// as they are now structure variables of QuantizationSpecs.
+std::unique_ptr<OperationPass<func::FuncOp>> CreateQuantizePass(
+    const quant::QuantizationSpecs& quant_specs,
+    const absl::flat_hash_set<std::string>& ops_blocklist = {},
+    const absl::flat_hash_set<std::string>& nodes_blocklist = {});
+
+std::unique_ptr<OperationPass<func::FuncOp>> CreateDefaultQuantizePass();
+
+std::unique_ptr<OperationPass<ModuleOp>> CreateLowerQuantAnnotationsPass();
+
+// Overloading of CreateQuantizePass which takes only necessary flags to reduce
+// the binary size.
+std::unique_ptr<OperationPass<func::FuncOp>> CreateQuantizePass(
+    bool verify_numeric = false, bool whole_model_verify = false,
+    bool legacy_float_scale = false,
+    const absl::flat_hash_set<std::string>& ops_blocklist = {},
+    const absl::flat_hash_set<std::string>& nodes_blocklist = {});
+
+// Creates an instance of the TensorFlow Lite dialect PrepareQuantize pass.
+std::unique_ptr<OperationPass<func::FuncOp>> CreatePrepareQuantizePass(
+    const quant::QuantizationSpecs& quant_specs);
+
+std::unique_ptr<OperationPass<func::FuncOp>> CreatePrepareQuantizePass();
+
+// Creates an instance of the TensorFlow Lite dialect
+// PrepareDynamicRangeQuantize pass.
+std::unique_ptr<OperationPass<func::FuncOp>>
+CreatePrepareDynamicRangeQuantizePass(
+    const quant::QuantizationSpecs& quant_specs);
+
+std::unique_ptr<OperationPass<func::FuncOp>>
+CreatePrepareDynamicRangeQuantizePass();
+
+// Creates an instance of the TensorFlow Lite dialect PostQuantize pass.
+std::unique_ptr<OperationPass<func::FuncOp>> CreatePostQuantizePass();
+std::unique_ptr<OperationPass<func::FuncOp>> CreatePostQuantizePass(
+    bool emit_quant_adaptor_ops, const quant::CustomOpMap& custom_op_map = {});
+
+// Creates an instance of the TensorFlow Lite dialect QuantizeVariables pass.
+std::unique_ptr<OperationPass<ModuleOp>> CreatePrepareQuantizeVariablesPass();
+
+// Creates an instance of the TensorFlow Lite pass that decomposes hybrid
+// quantization patterns to the same dense operation with tfl dequantization
+// and quantization patterns.
+std::unique_ptr<OperationPass<func::FuncOp>>
+CreateDecomposeHybridQuantizationPass();
+
+// Creates an instance of the TensorFlow Lite optimize op order pass.
+std::unique_ptr<OperationPass<func::FuncOp>> CreateOptimizeOpOrderPass();
+
+// Creates an instance of the TensorFlow Lite dialect TrimFunctions
+// pass.
+std::unique_ptr<OperationPass<ModuleOp>> CreateTrimFunctionsPass();
+
+std::unique_ptr<OperationPass<ModuleOp>> CreateTrimFunctionsPass(
+    const std::vector<std::string>& trim_funcs_allowlist);
+
+// Creates an instance of the TensorFlow Lite dialect PrepareCompositeFunctions
+// pass.
+std::unique_ptr<OperationPass<ModuleOp>> CreatePrepareCompositeFunctionsPass();
+
+// Creates an instance of the TensorFlow Lite dialect SplitMergedOperandsPass.
+inline std::unique_ptr<mlir::Pass> CreateSplitMergedOperandsPass() {
+  return Create<SplitMergedOperandsPass>();
+}
+
+// Creates an instance of the TensorFlow Lite dialect OptimizeFunctionalOpsPass.
+std::unique_ptr<OperationPass<ModuleOp>> CreateOptimizeFunctionalOpsPass();
+
+std::unique_ptr<OperationPass<func::FuncOp>> CreateModifyIONodesPass(
+    mlir::Type input_type, mlir::Type output_type);
+
+std::unique_ptr<OperationPass<func::FuncOp>> CreateModifyIONodesPass();
+
+// Creates an instance of the TensorFlow Lite dialect PostQuantizeRemoveQDQ
+// pass.
+std::unique_ptr<OperationPass<func::FuncOp>> CreatePostQuantizeRemoveQDQPass();
+
+// Creates an instance of the TensorFlow Lite dialect pass to add default
+// quantization parameters.
+std::unique_ptr<OperationPass<func::FuncOp>> CreateDefaultQuantParamsPass(
+    double default_min, double default_max, bool is_signed);
+
+std::unique_ptr<OperationPass<func::FuncOp>> CreateDefaultQuantParamsPass();
+
+// Creates an instance of the IdentifyDilatedConvPass.
+std::unique_ptr<OperationPass<func::FuncOp>> CreateIdentifyDilatedConvPass();
+
+// Creates function pass to legalize TF While to TFL While.
+std::unique_ptr<OperationPass<ModuleOp>> CreateLegalizeTFWhilePass();
+
+// Legalize tflite flex ops to TF ops.
+std::unique_ptr<OperationPass<func::FuncOp>> CreateLiftTfliteFlexOpsPass();
+
+// Creates an instance of the TensorFlow Lite dialect WhileOp outline pass.
+inline std::unique_ptr<mlir::Pass> CreateWhileOutlinePass() {
+  return Create<WhileOutlinePass>();
+}
+
+// Creates an instance of the TensorFlow Lite dialect IfOp outline pass.
+std::unique_ptr<OperationPass<ModuleOp>> CreateIfOutlinePass();
+
+// Creates a pass to remove operands of TFL WhileOp without changing outcomes.
+std::unique_ptr<OperationPass<func::FuncOp>> CreateReduceWhileOperandsPass();
+
+// Verifies runtime constraints.
+std::unique_ptr<OperationPass<func::FuncOp>> CreateRuntimeVerifyPass();
+
+// Creates raise custom ops pass, which legalize custom ops to TFL::CustomOp
+std::unique_ptr<OperationPass<func::FuncOp>> CreateRaiseCustomOpsPass();
+std::unique_ptr<OperationPass<func::FuncOp>> CreateRaiseCustomOpsPass(
+    const std::vector<std::string>& target_ops);
+
+// Creates raise custom ops pass, which legalize custom ops to TFL::CustomOp
+std::unique_ptr<OperationPass<func::FuncOp>> CreateLowerCustomOpsPass();
+
+// Inserts an TFL::CallOnce op when the tf_saved_model's session initialzer is
+// given.
+std::unique_ptr<OperationPass<ModuleOp>>
+CreateInsertCallOnceOpFromSessionInitializerPass();
+
+// Replace the tfl wrapped random function body with tfl.customOp.
+std::unique_ptr<OperationPass<func::FuncOp>> CreateLegalizeJaxRandomPass();
+
+// Creates a pass which is responsible for legalizing TensorFlow variables to
+// TensorFlow Lite variables.
+std::unique_ptr<OperationPass<ModuleOp>> CreateLegalizeVariablesPass();
+
+// Creates a pass which analyze the model whether it is safe to use
+// native TFLite variables or not.
+inline std::unique_ptr<mlir::Pass> CreateAnalyzeVariablesPass() {
+  return Create<AnalyzeVariablesPass>();
+}
+
+// Creates a pass which is responsible for legalizing TensorFlow static hash
+// tables to TensorFlow Lite hash tables.
+std::unique_ptr<OperationPass<ModuleOp>> CreateLegalizeHashTablesPass();
+
+// Creates get arithmetic count pass, which will calculate the arithmetic count
+// for each ops.
+std::unique_ptr<OperationPass<func::FuncOp>> CreateGetArithmeticCountPass();
+
+// Creates unfold large constant pass, which will replace large splat constant
+// tensors with fill op.
+inline std::unique_ptr<mlir::Pass> CreateUnfoldLargeSplatConstantPass() {
+  return Create<UnfoldLargeSplatConstantPass>();
+}
+
+// Creates a pass which is responsible for unfreezing mutable global tensors.
+inline std::unique_ptr<mlir::Pass> CreateUnfreezeMutableGlobalTensorsPass() {
+  return Create<UnfreezeMutableGlobalTensorsPass>();
+}
+
+// Creates a pass that adds control dependencies to keep the relative
+// execution order of operations with side effects frozen.
+std::unique_ptr<OperationPass<func::FuncOp>> CreatePinOpsWithSideEffectsPass();
+
+// Legalize TensorList Ops iff all of them are supported.
+inline std::unique_ptr<mlir::Pass> CreateLegalizeTensorListPass() {
+  return Create<LegalizeTensorListPass>();
+}
+
+// Reduce the type precision of some tensor types if all values within that
+// tensor are within the range of the reduced precision.
+std::unique_ptr<OperationPass<ModuleOp>> CreateReduceTypePrecisionPass();
+
+// Conservatively pushes transposes through element-wise ops to prepare
+// so redundant ones may be grouped and removed.
+inline std::unique_ptr<mlir::Pass> CreatePushTransposeThroughEwisePass() {
+  return Create<PushTransposeThroughEwisePass>();
+}
+
+// Create a pass that canonicalize the boundary values.
+inline std::unique_ptr<mlir::Pass> CreateCanonicalizeBoundaryValuePass() {
+  return Create<CanonicalizeBoundaryValuePass>();
+}
+
+// Creates a pass that brings operations into the same order as graph_info.cc.
+std::unique_ptr<OperationPass<func::FuncOp>>
+CreatePartitionedTopologicalSortPass();
+
+// dequant-split 추가
+std::unique_ptr<OperationPass<func::FuncOp>> CreateDequantSplit();
+
+// bias-contract 추가
+std::unique_ptr<OperationPass<func::FuncOp>> CreateBiasContract();
+
+// dequant-contract 추가
+std::unique_ptr<OperationPass<func::FuncOp>> CreateDequantContract();
+
+// reshape-to-4d 추가
+std::unique_ptr<OperationPass<func::FuncOp>> CreateReshapeTo4D();
+
+#define GEN_PASS_DECL_DEFAULTQUANTPARAMSPASS
+#define GEN_PASS_DECL_LEGALIZETFPASS
+#define GEN_PASS_DECL_LOWERSTATICTENSORLISTPASS
+#define GEN_PASS_DECL_MODIFYIONODESPASS
+#define GEN_PASS_DECL_POSTQUANTIZEPASS
+#define GEN_PASS_DECL_PREPARECOMPOSITEFUNCTIONSPASS
+#define GEN_PASS_DECL_PREPAREDYNAMICRANGEQUANTIZEPASS
+#define GEN_PASS_DECL_PREPAREQUANTIZEPASS
+#define GEN_PASS_DECL_PREPARETFPASS
+#define GEN_PASS_DECL_QUANTIZEPASS
+#define GEN_PASS_DECL_RAISECUSTOMOPSPASS
+#define GEN_PASS_DECL_TRIMFUNCTIONSPASS
+#define GEN_PASS_REGISTRATION
+#include "tensorflow/compiler/mlir/lite/transforms/passes.h.inc"
+
+// Creates an instance of the TensorFlow Lite dialect LegalizeTF pass.
+std::unique_ptr<OperationPass<func::FuncOp>> CreateLegalizeTFPass(
+    const LegalizeTFPassOptions& options);
+
+// Creates an instance of the TensorFlow Lite dialect PrepareTF pass.
+std::unique_ptr<OperationPass<func::FuncOp>> CreatePrepareTFPass(
+    const PrepareTFPassOptions& options);
+
+// Creates an instance of the TensorFlow Lite dialect LowerStaticTensorList
+// pass.
+std::unique_ptr<OperationPass<ModuleOp>> CreateLowerStaticTensorListPass(
+    const LowerStaticTensorListPassOptions& options);
+
+// Creates raise custom ops pass, which legalize custom ops to TFL::CustomOp
+std::unique_ptr<OperationPass<func::FuncOp>> CreateRaiseCustomOpsPass(
+    const RaiseCustomOpsPassOptions& options);
+
+// Creates an instance of the TensorFlow Lite dialect pass to add default
+// quantization parameters.
+std::unique_ptr<OperationPass<func::FuncOp>> CreateDefaultQuantParamsPass(
+    const DefaultQuantParamsPassOptions& options);
+
+inline void registerTensorFlowLitePasses() {
+  registerTensorFlowLiteTdPasses();
+  // Register TFLite Converter Passes
+  Register<UnfreezeMutableGlobalTensorsPass>();
+
+  // TF Legalization Passes
+  Register<AnalyzeVariablesPass>();
+  Register<LegalizeTensorListPass>();
+  Register<WhileOutlinePass>();
+
+  // TFL Optimization Passes
+  Register<OptimizePass, OptimizePassOptions>();
+  Register<OptimizeBatchMatmulPass>();
+  Register<UnfreezeMutableGlobalTensorsPass>();
+  Register<OptimizeBroadcastLikePass>();
+  Register<PushTransposeThroughEwisePass>();
+  Register<CanonicalizeBoundaryValuePass>();
+
+  // Other TFLite Passes
+  Register<UnfoldLargeSplatConstantPass>();
+  Register<SplitMergedOperandsPass>();
+}
+
+}  // namespace TFL
+
+}  // namespace mlir
+
+#endif  // TENSORFLOW_COMPILER_MLIR_LITE_TRANSFORMS_PASSES_H_
diff --git a/tensorflow/compiler/mlir/lite/transforms/passes.td b/tensorflow/compiler/mlir/lite/transforms/passes.td
new file mode 100644
index 00000000000..66a970d52ce
--- /dev/null
+++ b/tensorflow/compiler/mlir/lite/transforms/passes.td
@@ -0,0 +1,422 @@
+/* Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+
+include "mlir/Pass/PassBase.td"
+
+def DefaultQuantParamsPass : Pass<"tfl-default-quant", "mlir::func::FuncOp"> {
+  let summary = "Apply quantization with default quantization parameter";
+  let constructor = "CreateDefaultQuantParamsPass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect"];
+  let options = [
+    Option<"default_min_", "default-min", "double", "-1.0",
+               "Default minimum value for TFLite quantization">,
+    Option<"default_max_", "default-max", "double", "1.0",
+               "Default maximum value for TFLite quantization">,
+    Option<"is_signed_", "is-signed", "bool", "false",
+               "Is the corresponding integer signed">,
+  ];
+}
+def DecomposeHybridQuantizationPass : Pass<"tfl-decompose-hybrid-quantization", "mlir::func::FuncOp"> {
+  let summary = "Decomposes hybridge quantization to explicit quantize / dequantize";
+  let description = [{
+      Decomposes (with explicit quantize/dequantize ops) selected math
+      operations which exist in the model with hybrid quantization
+      (some arguments/results left in floating point).
+  }];
+  let constructor = "CreateDecomposeHybridQuantizationPass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect"];
+}
+
+def IdentifyDilatedConvPass : Pass<"tfl-identify-dilated-conv", "mlir::func::FuncOp"> {
+  let summary = "Convert dense tensor to sparse format.";
+  let constructor = "CreateIdentifyDilatedConvPass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect"];
+}
+
+def GetArithmeticCountPass : Pass<"tfl-get-arithmetic-count", "mlir::func::FuncOp"> {
+  let summary = "Calculate arithmetic count for tfl operations.";
+  let constructor = "CreateGetArithmeticCountPass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect"];
+}
+
+def InsertCallOnceOpFromSessionInitializerPass : Pass<"tfl-insert-call-once-op", "mlir::ModuleOp"> {
+  let summary = "Insert CallOnce op when tf_saved_model's session initializer is give.";
+  let constructor = "CreateInsertCallOnceOpFromSessionInitializerPass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect"];
+}
+
+def LegalizeHashTablesPass : Pass<"tfl-legalize-hashtables-tf", "mlir::ModuleOp"> {
+  let summary = "Legalize TensorFlow hash tables to TensorFlow Lite dialect.";
+  let constructor = "CreateLegalizeHashTablesPass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect"];
+}
+
+def LegalizeJaxRandomPass : Pass<"tfl-legalize-random", "mlir::func::FuncOp"> {
+  let summary = "Replace jax.random.uniform/normal with tfl.custom.";
+  let constructor = "CreateLegalizeJaxRandomPass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect", "stablehlo::StablehloDialect"];
+}
+
+def LegalizeTFPass : Pass<"tfl-legalize-tf", "mlir::func::FuncOp"> {
+  let summary = "Legalize from TensorFlow to TensorFlow Lite dialect.";
+  let constructor = "CreateLegalizeTFPass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect" ,
+    "quant::QuantDialect",
+    "quantfork::QuantizationForkDialect"
+  ];
+  let options = [
+      Option<"run_tfl_runtime_verification_", "run-tfl-runtime-verification",
+             "bool", "true", "Allow tfl runtime verification.">,
+      Option<"preserve_assert_op_", "preserve-assert-op",
+             "bool", "false", "Preserve AssertOp during tfl legalization.">,
+  ];
+}
+
+def LegalizeWhilePass : Pass<"tfl-legalize-tf-while", "mlir::ModuleOp"> {
+  let summary = "Legalize from TensorFlow While to TensorFlow Lite While.";
+  let constructor = "CreateLegalizeTFWhilePass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect"];
+}
+
+def LegalizeVariablesPass : Pass<"tfl-legalize-variables-tf", "mlir::ModuleOp"> {
+  let summary = "Legalize TensorFlow variables to TensorFlow Lite dialect.";
+  let constructor = "CreateLegalizeVariablesPass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect"];
+}
+
+def LiftTfliteFlexOpsPass : Pass<"tfl-lift-tflite-flex-ops", "mlir::func::FuncOp"> {
+  let summary = "Lifts TFLite Custom ops into TF dialect operations.";
+  let constructor = "CreateLiftTfliteFlexOpsPass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect"];
+}
+
+def LowerStaticTensorListPass : Pass<"tfl-lower-static-tensor-list", "mlir::ModuleOp"> {
+  let summary = "Lower TensorList ops within TensorFlow Lite dialect.";
+  let constructor = "CreateLowerStaticTensorListPass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect"];
+  let options = [
+      Option<"allow_tensorlist_pass_through_", "allow-tensorlist-pass-through",
+             "bool", "false",
+             "When specified to true, if the tensorlist ops can't be properly "
+             "legalized by this pass, then the IR won't be changed so that "
+             "tensorlist ops can pass through (default false).">,
+      Option<
+        "default_to_single_batch_", "default-to-single-batch", "bool", "false",
+        "When specified to true, if the tensorlist ops has unspecified batch "
+        "size, this pass will assume that the batch size is one to proceed "
+        "tensorlist op lowering (default true)">,
+      Option<"enable_dynamic_update_slice_", "enable-dynamic-update-slice",
+             "bool", "false", "When specified to true, lower TensorListSetItem with "
+             "DynamicUpdateSlice op (default false).">,
+  ];
+}
+
+def ModifyIONodesPass : Pass<"tfl-modify-io-nodes", "mlir::func::FuncOp"> {
+  let summary = "Modify the type of the model io nodes";
+  let description = [{
+      This transformation pass modifies the input and output types of the function
+      to what are specified. The task was not just adding cast operations, but,
+      instead, using tfl.quantize and tfl.dequantize ops to scale the tensors.
+  }];
+  let constructor = "CreateModifyIONodesPass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect"];
+  let options = [
+      ListOption<"io_node_types_", "test-io-types", "std::string",
+                 "comma separated type strings. Allowed values: 'int8', 'uint8', 'float32']">,
+  ];
+}
+
+def OptimizeFunctionalOpsPass : Pass<"tfl-optimize-functional-ops", "mlir::ModuleOp"> {
+  let summary = "Optimize TensorFlow functional op";
+  let constructor = "CreateOptimizeFunctionalOpsPass()";
+}
+
+def OptimizeOpOrderPass : Pass<"tfl-optimize-op-order", "mlir::func::FuncOp"> {
+  let summary = "Optimize the execution order of the ops.";
+  let description = [{
+      This transformation pass optimizes the op execution order of the ops in
+      the model.
+  }];
+  let constructor = "CreateOptimizeOpOrderPass()";
+}
+
+def PartitionedTopologicalSortPass : Pass<"tfl-partitioned-topological-sort", "mlir::func::FuncOp"> {
+  let summary = "Re-sort execution order such that delegated ops stay together";
+  let constructor = "CreatePartitionedTopologicalSortPass()";
+    let description = [{
+      This transformation reorders operations such that operations that will be
+      executed by the Flex delegate will be followed by another Flex delegated
+      operator, if possible. The reordering uses the same greedy procedure that
+      is executed at runtime (in tensorflow/lite/graph_info.cc.)
+      This allows us to have an IR of the model that is in the same execution order
+      as it will have at runtime (provided Flex is the only delegate present); this
+      allows us to do optimizations such as rematerialization.
+    }];
+  let dependentDialects = ["TFL::TensorFlowLiteDialect"];
+}
+
+def PinOpsWithSideEffectsPass : Pass<"tfl-pin-ops-with-side-effects", "mlir::func::FuncOp"> {
+  let summary = "Pin operators with side effects";
+  let description = [{
+      This transformation pass wraps operations that have or depend on side effects in
+      TFL::ControlNodeOp, which depend on the control token generated by the most recent
+      preceding such operation, if any. This copies the logic that is currently executed
+      at runtime to enforce that the relative order of side-effectful operations is
+      preserved and expresses it in terms of control dependencies.
+
+      For purposes of this pass, an operator is considered to have/depend on side effects if
+        - it calls a different function
+        - it depends on or generates resource variable handles
+  }];
+  let constructor = "CreatePinOpsWithSideEffectsPass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect"];
+}
+
+def PostQuantizePass : Pass<"tfl-post-quantize", "mlir::func::FuncOp"> {
+  let summary = "Apply post quantization clean up after quantization.";
+  let constructor = "CreatePostQuantizePass()";
+  let options = [
+      Option<"emit_quant_adaptor_ops_", "emit-quant-adaptor-ops",
+             "bool", "false",
+             "Enable canonicalization during optimization pass.">,
+      Option<"enable_custom_op_no_side_effect_", "enable-no-side-effect",
+            "std::string", "", "Specifies which custom ops are NoSideEffect.">,
+  ];
+}
+
+def PostQuantizeRemoveQDQPass : Pass<"tfl-post-quantize-remove-qdq", "mlir::func::FuncOp"> {
+  let summary = "Remove qdq from input and output nodes after quantization.";
+  let constructor = "CreatePostQuantizeRemoveQDQPass()";
+}
+
+def PrepareCompositeFunctionsPass : Pass<"tfl-prepare-composite-funcs-tf", "mlir::ModuleOp"> {
+  let summary = "Prepares composite functions in Tensorflow dialect of MLIR.";
+  let constructor = "CreatePrepareCompositeFunctionsPass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect"];
+  let description = [{
+      This pass uses mechanisms listed in RFC:
+      https://github.com/tensorflow/community/pull/113
+      It prepares composite functions that are attributed to indicate
+      a specific interface (LSTM, SVDF, Embedding lookup etc.) by replacing the
+      body with the corresponding fused TFLite op. The replacement need not
+      always be a fused op, though that is the primary use case.
+  }];
+  let options = [
+      Option<"tfl_fuse_tftext_", "fuse-tftext", "bool", "false",
+             "Fuse TF.Text API ops when it's true">
+  ];
+
+}
+
+def PrepareQuantizePass : Pass<"tfl-prepare-quantize", "mlir::func::FuncOp"> {
+  let summary = "Remove qdq from input and output nodes after quantization.";
+  let constructor = "CreatePrepareQuantizePass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect",
+    "quant::QuantDialect",
+    "quantfork::QuantizationForkDialect"
+  ];
+  let options = [
+      ListOption<"quantize_allowlist_", "quantize-allowlist", "std::string",
+                 "comma separated list of allowlisted functions to be quantized. Only used in tests">,
+      Option<"quantize_signed_", "quantize-signed", "bool", "false",
+             "signed inference type. Only used in tests">,
+      Option<"activation_number_of_bits_", "activation-number-of-bits", "int", "8",
+             "number of bits for inference type. Only used in tests">,
+      Option<"post_training_quantize_", "post-training-quantize", "bool", "false",
+             "enable post training quantization. Only used in tests">,
+      Option<"legacy_float_scale_", "legacy-float-scale", "bool", "false",
+             "calculate quantization scales in float instead of double">,
+      Option<"disable_per_channel_", "disable-per-channel", "bool", "false",
+             "Whether disable per-channel quantized weights.">,
+      Option<"disable_set_input_nodes_quantization_params_",
+             "disable-set-input-nodes-quantization-params",
+             "bool", "false",
+             "Whether disable set input nodes quantization parameters.">,
+      Option<"is_qdq_conversion_", "is-qdq-conversion", "bool", "false",
+             "Whether the source graph is a QDQ model intended for conversion only.">,
+      ListOption<"input_ranges_", "input-ranges", "std::string",
+                 "comma separated list of pairs specifying input ranges which correspond to positional func input arguments. Must be in the format '<min double>|<max double>,<min double>|<max double>'. Only used in tests.">,
+  ];
+}
+
+def PrepareDynamicRangeQuantizePass : Pass<"tfl-prepare-quantize-dynamic-range", "mlir::func::FuncOp"> {
+  let summary = "Prepare TFL dialect for dynamic range quantization.";
+  let constructor = "CreatePrepareDynamicRangeQuantizePass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect",
+    "mlir::quant::QuantDialect",
+    "mlir::quantfork::QuantizationForkDialect"
+  ];
+  let options = [
+      Option<"enable_dynamic_range_per_channel_quantization_",
+              "enable-dynamic-range-per-channel-quantization", "bool",
+              "true", "Whether enable per-channel quantized weights.">,
+      Option<"enable_dynamic_range_per_channel_quantization_for_dense_layers_",
+              "enable-dynamic-range-per-channel-quantization-for-dense-layers", "bool",
+              "true", "Whether enable per-channel quantized weights for Fully Connected layers (default is per tensor).">,
+      Option<"min_elements_for_weights_",
+              "min-elements-for-weights", "int64_t", "1024",
+              "The minimum number of elements in a weights array required to apply quantization.">,
+      Option<"enable_float16_quantization_",
+              "enable-float16-quantization", "bool",
+              "false", "Whether apply float16 quantization. If false, int8 quantization is applied.">,
+      Option<"enable_custom_op_quantization_",
+              "enable-custom-op-quantization", "std::string", "",
+              "Specifies which pairs of a custom op and indices are quantizable where the indices are separated with a space.">,
+  ];
+}
+
+def PrepareTFPass : Pass<"tfl-prepare-tf", "mlir::func::FuncOp"> {
+  let summary = "Prepare TF for legalization to TensorFlow Lite dialect.";
+  let constructor = "CreatePrepareTFPass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect",
+    "mlir::quant::QuantDialect",
+    "mlir::quantfork::QuantizationForkDialect",
+    "mhlo::MhloDialect"
+  ];
+  let options = [
+      Option<"unfold_batch_matmul_", "unfold_batchmatmul",
+             "bool", "true",
+             "Unfold BatchMatMul into individual MatMul ops.">,
+      Option<"allow_bf16_and_f16_type_legalization_", "allow-bf16-and-f16-type-legalization",
+             "bool", "false",
+             "Allow bf16 type legalization.">,
+      Option<"use_fake_quant_num_bits_", "use-fake-quant-num-bits",
+             "bool", "false",
+             "Use quantization calculated from fake quant attributes.">,
+  ];
+}
+
+def QuantizePass : Pass<"tfl-quantize", "mlir::func::FuncOp"> {
+  let summary = "Apply quantization on models in TensorFlow Lite dialect.";
+  let constructor = "CreateDefaultQuantizePass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect",
+    "mlir::quant::QuantDialect",
+    "mlir::quantfork::QuantizationForkDialect"
+  ];
+
+  let options = [
+      Option<"enable_numeric_verify_", "numeric-verify",
+             "bool", "false",
+             "Whether verify numericals at runtime.">,
+      Option<"error_tolerance_", "error-tolerance",
+             "float", "5.0f",
+             "Error tolerance for numeric verify. Valid when `-numeric-verify` is set.">,
+      Option<"enable_whole_model_verify_", "whole-model-verify",
+             "bool", "false",
+             "Whether verify numericals layer by layer or whole model. Valid when `-numeric-verify` is set.">,
+      Option<"enable_log_if_failed_", "log-if-failed",
+             "bool", "false",
+             "Whether verify numericals with thresholding tolerance. Valid when `-numeric-verify` is set.">,
+      Option<"enable_dynamic_range_quantization_", "enable-dynamic-range-quantization",
+             "bool", "false",
+             "Whether run post-training dynamic range quantization pass">,
+      Option<"enable_weight_only_quantization_", "enable-weight-only-quantization",
+             "bool", "false",
+             "Whether to run weight-only for post-training dynamic range quantization pass">,
+      Option<"enable_legacy_quantize_", "legacy-quantize",
+             "bool", "false",
+             "Use legacy quantize mode in test. Valid when `-legacy-quantize` is set.">,
+      ListOption<"ops_blocklist_flag_", "ops-blocklist",
+             "std::string", "Names of ops to blocklist from quantization">,
+      ListOption<"nodes_blocklist_flag_", "locs-blocklist",
+             "std::string", "Names of location to blocklist from quantization">,
+      Option<"enable_custom_op_weight_only_", "enable-custom-op-weight-only",
+             "std::string", "", "Specifies which custom ops are weight-only.">,
+      Option<"enable_float16_quantization_",
+              "enable-float16-quantization", "bool",
+              "false", "Whether apply float16 quantization. If false, int8 quantization is applied.">,
+  ];
+}
+
+def LowerQuantAnnotationsPass : Pass<"tfl-lower-quant-annotations", "mlir::ModuleOp"> {
+  let summary = "Lowers the quantization annotations marked by composites to the TFLite dialect.";
+  let constructor = "CreateLowerQuantAnnotationsPass()";
+  let dependentDialects = [
+    "TFL::TensorFlowLiteDialect",
+    "mlir::quant::QuantDialect",
+    "TF::TensorFlowDialect",
+    "stablehlo::StablehloDialect"
+  ];
+}
+
+def QuantizeVariablesPass : Pass<"tfl-quantize-variables", "mlir::ModuleOp"> {
+  let summary = "Quantize variables";
+  let constructor = "CreatePrepareQuantizeVariablesPass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect"];
+}
+
+def RaiseCustomOpsPass : Pass<"tfl-raise-custom-ops", "mlir::func::FuncOp"> {
+  let summary = "Raise custom ops into tflite dialect.";
+  let constructor = "CreateRaiseCustomOpsPass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect"];
+
+  let options = [
+      ListOption<"target_ops_", "test-raise-tf-targets", "std::string",
+             "comma separated list of target op names to be wrapped. Only used in tests">,
+  ];
+}
+
+def ReduceWhileOperandsPass : Pass<"tfl-reduce-while", "mlir::func::FuncOp"> {
+  let summary = "Reduce the number of operands and results of a whlieOp..";
+  let constructor = "CreateReduceWhileOperandsPass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect", "TF::TensorFlowDialect"];
+}
+
+def RuntimeVerifyPass : Pass<"tfl-runtime-verify", "mlir::func::FuncOp"> {
+  let summary = "TFLite runtime verification";
+  let constructor = "CreateRuntimeVerifyPass()";
+}
+
+def TrimFunctionsPass : Pass<"tfl-trim-funcs-tf", "mlir::ModuleOp"> {
+  let summary = "Trim functions to restrict them to a specified allowlist prior to legalization to TensorFlow lite dialect";
+  let constructor = "CreateTrimFunctionsPass()";
+  let options = [
+      ListOption<"trim_funcs_allowlist_", "trim-funcs-allowlist", "std::string",
+                 "comma separated list of allowlisted functions. The first "
+                 "function specified will be used as main">
+  ];
+}
+
+def IfOutlinePass : Pass<"tfl-if-outline", "mlir::ModuleOp"> {
+  let summary = "Hoist if op regions into functions";
+  let constructor = "CreateIfOutlinePass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect"];
+}
+
+def ReduceTypePrecisionPass : Pass<"tfl-reduce-type-precision", "mlir::ModuleOp"> {
+  let summary = "Reduce some tensor types' precision if all values are within range.";
+  let constructor = "CreateReduceTypePrecisionPass()";
+  let dependentDialects = ["TFL::TensorFlowLiteDialect"];
+}
+
+def DequantSplit : Pass<"dequant-split", "mlir::func::FuncOp"> {
+  let summary = "Split dequant op";
+  let constructor = "CreateDequantSplit()";
+}
+
+def BiasContract : Pass<"bias-contract", "mlir::func::FuncOp"> {
+  let summary = "Contract FC biases <1x1x1xX> -> <X>";
+  let constructor = "CreateBiasContract()";
+}
+
+def DequantContract : Pass<"dequant-contract", "mlir::func::FuncOp"> {
+  let summary = "Contract 5D dequantize ops <AxBxCxDxE> -> <(A*B)XCXDXE>";
+  let constructor = "CreateDequantContract()";
+}
+
+def ReshapeTo4D : Pass<"reshape-to-4d", "mlir::func::FuncOp"> {
+  let summary = "Reshape inputs of FC ops to 4D";
+  let constructor = "CreateReshapeTo4D()";
+}
-- 
2.34.1

